{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector,Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180101</td>\n",
       "      <td>25708</td>\n",
       "      <td>23638</td>\n",
       "      <td>2070</td>\n",
       "      <td>8.76</td>\n",
       "      <td>279.707</td>\n",
       "      <td>189.179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.8</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4</td>\n",
       "      <td>49.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180102</td>\n",
       "      <td>29536</td>\n",
       "      <td>27816</td>\n",
       "      <td>1720</td>\n",
       "      <td>6.18</td>\n",
       "      <td>321.468</td>\n",
       "      <td>217.423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.9</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>43.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180103</td>\n",
       "      <td>30132</td>\n",
       "      <td>28253</td>\n",
       "      <td>1879</td>\n",
       "      <td>6.65</td>\n",
       "      <td>334.264</td>\n",
       "      <td>226.077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.9</td>\n",
       "      <td>...</td>\n",
       "      <td>24.6</td>\n",
       "      <td>32.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>22.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2     3     4        5        6  7  8     9  ...    61  \\\n",
       "1  20180101  25708  23638  2070  8.76  279.707  189.179  0  0  98.8 ...  29.4   \n",
       "2  20180102  29536  27816  1720  6.18  321.468  217.423  0  0  98.9 ...    31   \n",
       "3  20180103  30132  28253  1879  6.65  334.264  226.077  0  0  98.9 ...  24.6   \n",
       "\n",
       "     62   63   64   65   66 67    68    69 70  \n",
       "1  49.5  2.7  1.6  4.2    3  0  15.5  35.1  0  \n",
       "2  43.9  3.9  1.6  4.4    3  0  11.6  13.9  0  \n",
       "3  32.3  3.9  1.6  3.9  2.5  0  22.3   6.8  0  \n",
       "\n",
       "[3 rows x 71 columns]"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2018 = pd.read_csv('台灣電力公司_過去電力供需資訊2018.csv', engine='python',header = None)\n",
    "train2018.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2018 = train2018.drop(train2018.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180101</td>\n",
       "      <td>25708</td>\n",
       "      <td>23638</td>\n",
       "      <td>2070</td>\n",
       "      <td>8.76</td>\n",
       "      <td>279.707</td>\n",
       "      <td>189.179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.8</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4</td>\n",
       "      <td>49.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180102</td>\n",
       "      <td>29536</td>\n",
       "      <td>27816</td>\n",
       "      <td>1720</td>\n",
       "      <td>6.18</td>\n",
       "      <td>321.468</td>\n",
       "      <td>217.423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.9</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>43.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180103</td>\n",
       "      <td>30132</td>\n",
       "      <td>28253</td>\n",
       "      <td>1879</td>\n",
       "      <td>6.65</td>\n",
       "      <td>334.264</td>\n",
       "      <td>226.077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.9</td>\n",
       "      <td>...</td>\n",
       "      <td>24.6</td>\n",
       "      <td>32.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>22.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180104</td>\n",
       "      <td>30716</td>\n",
       "      <td>28757</td>\n",
       "      <td>1959</td>\n",
       "      <td>6.81</td>\n",
       "      <td>337.945</td>\n",
       "      <td>228.567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.8</td>\n",
       "      <td>...</td>\n",
       "      <td>14.8</td>\n",
       "      <td>45.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20180105</td>\n",
       "      <td>30401</td>\n",
       "      <td>28260</td>\n",
       "      <td>2141</td>\n",
       "      <td>7.58</td>\n",
       "      <td>337.418</td>\n",
       "      <td>228.211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>56.2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2     3     4        5        6  7  8     9  ...   \\\n",
       "1  20180101  25708  23638  2070  8.76  279.707  189.179  0  0  98.8 ...    \n",
       "2  20180102  29536  27816  1720  6.18  321.468  217.423  0  0  98.9 ...    \n",
       "3  20180103  30132  28253  1879  6.65  334.264  226.077  0  0  98.9 ...    \n",
       "4  20180104  30716  28757  1959  6.81  337.945  228.567  0  0  98.8 ...    \n",
       "5  20180105  30401  28260  2141  7.58  337.418  228.211  0  0  98.7 ...    \n",
       "\n",
       "     61    62   63   64   65   66 67    68    69   70  \n",
       "1  29.4  49.5  2.7  1.6  4.2    3  0  15.5  35.1    0  \n",
       "2    31  43.9  3.9  1.6  4.4    3  0  11.6  13.9    0  \n",
       "3  24.6  32.3  3.9  1.6  3.9  2.5  0  22.3   6.8    0  \n",
       "4  14.8  45.2  3.9  1.6  3.9    3  0  22.1  19.1    0  \n",
       "5  15.7  33.3  1.5  1.6    0  1.8  0  22.1  56.2  0.4  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train2018.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train2018[[\"日期\"]] = train2018[\"日期\"].astype(\"float\")\n",
    "train2018.iloc[:,0] = pd.to_datetime(train2018.iloc[:,0], format='%Y%m%d')\n",
    "train2019.iloc[:,0] = pd.to_datetime(train2019.iloc[:,0], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train2018.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2018.iloc[:,1:] = train2018.iloc[:,1:].astype(\"float64\")\n",
    "#train2018.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看特定變數欄\n",
    "train_y = train2018.iloc[:,2]\n",
    "#train_y.head(3)\n",
    "#train2018 = train2018.drop(2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>25708.0</td>\n",
       "      <td>23638.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>8.76</td>\n",
       "      <td>279.707</td>\n",
       "      <td>189.179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.8</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4</td>\n",
       "      <td>49.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>29536.0</td>\n",
       "      <td>27816.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>321.468</td>\n",
       "      <td>217.423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.9</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>30132.0</td>\n",
       "      <td>28253.0</td>\n",
       "      <td>1879.0</td>\n",
       "      <td>6.65</td>\n",
       "      <td>334.264</td>\n",
       "      <td>226.077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.9</td>\n",
       "      <td>...</td>\n",
       "      <td>24.6</td>\n",
       "      <td>32.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>30716.0</td>\n",
       "      <td>28757.0</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>6.81</td>\n",
       "      <td>337.945</td>\n",
       "      <td>228.567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.8</td>\n",
       "      <td>...</td>\n",
       "      <td>14.8</td>\n",
       "      <td>45.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>30401.0</td>\n",
       "      <td>28260.0</td>\n",
       "      <td>2141.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>337.418</td>\n",
       "      <td>228.211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>56.2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2       3     4        5        6    7    8   \\\n",
       "1 2018-01-01  25708.0  23638.0  2070.0  8.76  279.707  189.179  0.0  0.0   \n",
       "2 2018-01-02  29536.0  27816.0  1720.0  6.18  321.468  217.423  0.0  0.0   \n",
       "3 2018-01-03  30132.0  28253.0  1879.0  6.65  334.264  226.077  0.0  0.0   \n",
       "4 2018-01-04  30716.0  28757.0  1959.0  6.81  337.945  228.567  0.0  0.0   \n",
       "5 2018-01-05  30401.0  28260.0  2141.0  7.58  337.418  228.211  0.0  0.0   \n",
       "\n",
       "     9  ...     61    62   63   64   65   66   67    68    69   70  \n",
       "1  98.8 ...   29.4  49.5  2.7  1.6  4.2  3.0  0.0  15.5  35.1  0.0  \n",
       "2  98.9 ...   31.0  43.9  3.9  1.6  4.4  3.0  0.0  11.6  13.9  0.0  \n",
       "3  98.9 ...   24.6  32.3  3.9  1.6  3.9  2.5  0.0  22.3   6.8  0.0  \n",
       "4  98.8 ...   14.8  45.2  3.9  1.6  3.9  3.0  0.0  22.1  19.1  0.0  \n",
       "5  98.7 ...   15.7  33.3  1.5  1.6  0.0  1.8  0.0  22.1  56.2  0.4  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2018 = train2018.loc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2018[\"year\"] = train2018.loc[:,0].dt.year\n",
    "train2018[\"month\"] = train2018.loc[:,0].dt.month\n",
    "train2018[\"date\"] = train2018.loc[:,0].dt.day\n",
    "train2018[\"day\"] = train2018.loc[:,0].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2018 = train2018.drop(0, axis=1)\n",
    "train2018 = train2018.drop(1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2018.columns = [\"y\", \"year\", \"month\", \"date\", \"day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23638.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27816.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28253.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28757.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28260.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         y  year  month  date  day\n",
       "1  23638.0  2018      1     1    0\n",
       "2  27816.0  2018      1     2    1\n",
       "3  28253.0  2018      1     3    2\n",
       "4  28757.0  2018      1     4    3\n",
       "5  28260.0  2018      1     5    4"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2019[\"year\"] = train2019.loc[:,0].dt.year\n",
    "train2019[\"month\"] = train2019.loc[:,0].dt.month\n",
    "train2019[\"date\"] = train2019.loc[:,0].dt.day\n",
    "train2019[\"day\"] = train2019.loc[:,0].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2019 = train2019.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2019.columns = [\"y\", \"year\", \"month\", \"date\", \"day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2470.9</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2338.2</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2291.5</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021.4</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999.2</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y  year  month  date  day\n",
       "1  2470.9  2019      2     1    4\n",
       "2  2338.2  2019      2     2    5\n",
       "3  2291.5  2019      2     3    6\n",
       "4  2021.4  2019      2     4    0\n",
       "5  1999.2  2019      2     5    1"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.concat([train2018, train2019], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    norm = df.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindata.iloc[:,1] = \n",
    "traindata.iloc[:,1:] = normalize(traindata.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y  year  month      date       day\n",
       "1  23638   0.0    0.0  0.000000  0.000000\n",
       "2  27816   0.0    0.0  0.033333  0.166667\n",
       "3  28253   0.0    0.0  0.066667  0.333333\n",
       "4  28757   0.0    0.0  0.100000  0.500000\n",
       "5  28260   0.0    0.0  0.133333  0.666667"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector,Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastDay=7, futureDay=7):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureDay-pastDay):\n",
    "        X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
    "        Y_train.append(np.array(train.iloc[i+pastDay:i+pastDay+futureDay][\"y\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X,Y):\n",
    "    np.random.seed(10)\n",
    "    randomList = np.arange(X.shape[0])\n",
    "    np.random.shuffle(randomList)\n",
    "    return X[randomList], Y[randomList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X,Y,rate):\n",
    "    X_train = X[int(X.shape[0]*rate):]\n",
    "    Y_train = Y[int(Y.shape[0]*rate):]\n",
    "    X_val = X[:int(X.shape[0]*rate)]\n",
    "    Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildManyToManyModel(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_length=shape[1], input_dim=shape[2], return_sequences=True))\n",
    "    # output shape: (5, 1)\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the last day and next day \n",
    "X_train, Y_train = buildTrain(traindata, 7, 7)\n",
    "#X_train, Y_train = shuffle(X_train, Y_train)\n",
    "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 7, 5)\n",
      "(44, 7, 5)\n",
      "(397, 7)\n",
      "(44, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "d:\\python\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(10, return_sequences=True, input_shape=(7, 5))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_44 (LSTM)               (None, 7, 10)             640       \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 7, 1)              11        \n",
      "=================================================================\n",
      "Total params: 651\n",
      "Trainable params: 651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 397 samples, validate on 44 samples\n",
      "Epoch 1/1000\n",
      "397/397 [==============================] - ETA: 5s - loss: 763932160.000 - 3s 7ms/step - loss: 788253248.8060 - val_loss: 708017728.0000\n",
      "Epoch 2/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773671104.000 - 0s 75us/step - loss: 788252382.6297 - val_loss: 708016768.0000\n",
      "Epoch 3/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776752256.000 - 0s 58us/step - loss: 788251449.3904 - val_loss: 708015872.0000\n",
      "Epoch 4/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814464704.000 - 0s 60us/step - loss: 788250559.1940 - val_loss: 708014848.0000\n",
      "Epoch 5/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 810581632.000 - 0s 60us/step - loss: 788249613.7028 - val_loss: 708013952.0000\n",
      "Epoch 6/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792755520.000 - 0s 53us/step - loss: 788248715.6071 - val_loss: 708013056.0000\n",
      "Epoch 7/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 760714496.000 - 0s 58us/step - loss: 788247745.4509 - val_loss: 708012096.0000\n",
      "Epoch 8/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790819520.000 - 0s 53us/step - loss: 788246827.8489 - val_loss: 708011136.0000\n",
      "Epoch 9/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796127232.000 - 0s 60us/step - loss: 788245886.7103 - val_loss: 708010240.0000\n",
      "Epoch 10/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811040384.000 - 0s 55us/step - loss: 788244965.0781 - val_loss: 708009216.0000\n",
      "Epoch 11/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793709440.000 - 0s 60us/step - loss: 788244012.3325 - val_loss: 708008256.0000\n",
      "Epoch 12/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783734784.000 - 0s 63us/step - loss: 788243056.8463 - val_loss: 708007360.0000\n",
      "Epoch 13/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777411008.000 - 0s 55us/step - loss: 788242122.8010 - val_loss: 708006464.0000\n",
      "Epoch 14/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772831872.000 - 0s 58us/step - loss: 788241225.3501 - val_loss: 708005440.0000\n",
      "Epoch 15/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781542912.000 - 0s 55us/step - loss: 788240258.4181 - val_loss: 708004480.0000\n",
      "Epoch 16/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 808521856.000 - 0s 55us/step - loss: 788239290.3577 - val_loss: 708003520.0000\n",
      "Epoch 17/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 821548672.000 - 0s 50us/step - loss: 788238341.1587 - val_loss: 708002624.0000\n",
      "Epoch 18/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776178944.000 - 0s 53us/step - loss: 788237427.1033 - val_loss: 708001664.0000\n",
      "Epoch 19/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 804686336.000 - 0s 58us/step - loss: 788236473.3904 - val_loss: 708000704.0000\n",
      "Epoch 20/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785155968.000 - 0s 60us/step - loss: 788235578.3577 - val_loss: 707999872.0000\n",
      "Epoch 21/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806395392.000 - 0s 63us/step - loss: 788234636.2519 - val_loss: 707998848.0000\n",
      "Epoch 22/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 803255360.000 - 0s 60us/step - loss: 788233724.1310 - val_loss: 707997952.0000\n",
      "Epoch 23/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807643072.000 - 0s 55us/step - loss: 788232749.7834 - val_loss: 707996928.0000\n",
      "Epoch 24/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762062336.000 - 0s 60us/step - loss: 788231845.7229 - val_loss: 707996032.0000\n",
      "Epoch 25/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 789310400.000 - 0s 58us/step - loss: 788230943.2746 - val_loss: 707995200.0000\n",
      "Epoch 26/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767831616.000 - 0s 55us/step - loss: 788230041.4710 - val_loss: 707994176.0000\n",
      "Epoch 27/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 824434688.000 - 0s 60us/step - loss: 788229127.7380 - val_loss: 707993216.0000\n",
      "Epoch 28/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797337024.000 - 0s 60us/step - loss: 788228168.3829 - val_loss: 707992320.0000\n",
      "Epoch 29/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783283584.000 - 0s 55us/step - loss: 788227224.3426 - val_loss: 707991424.0000\n",
      "Epoch 30/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 803756672.000 - 0s 53us/step - loss: 788226305.1285 - val_loss: 707990464.0000\n",
      "Epoch 31/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790127616.000 - 0s 55us/step - loss: 788225388.0101 - val_loss: 707989504.0000\n",
      "Epoch 32/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 752736384.000 - 0s 60us/step - loss: 788224471.0529 - val_loss: 707988544.0000\n",
      "Epoch 33/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769318400.000 - 0s 58us/step - loss: 788223544.1008 - val_loss: 707987648.0000\n",
      "Epoch 34/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807099456.000 - 0s 60us/step - loss: 788222558.3073 - val_loss: 707986688.0000\n",
      "Epoch 35/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802095872.000 - 0s 55us/step - loss: 788221667.4660 - val_loss: 707985728.0000\n",
      "Epoch 36/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 823646336.000 - 0s 58us/step - loss: 788220703.5970 - val_loss: 707984832.0000\n",
      "Epoch 37/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 736570752.000 - 0s 55us/step - loss: 788219753.4307 - val_loss: 707983872.0000\n",
      "Epoch 38/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 810514944.000 - 0s 55us/step - loss: 788218872.4232 - val_loss: 707982912.0000\n",
      "Epoch 39/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 812959232.000 - 0s 55us/step - loss: 788217904.8463 - val_loss: 707981952.0000\n",
      "Epoch 40/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 808060800.000 - 0s 60us/step - loss: 788216990.1461 - val_loss: 707981056.0000\n",
      "Epoch 41/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 760024320.000 - 0s 60us/step - loss: 788216051.4257 - val_loss: 707980096.0000\n",
      "Epoch 42/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784560192.000 - 0s 55us/step - loss: 788215103.1940 - val_loss: 707979200.0000\n",
      "Epoch 43/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 743741312.000 - 0s 58us/step - loss: 788214172.8564 - val_loss: 707978176.0000\n",
      "Epoch 44/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796537984.000 - 0s 58us/step - loss: 788213262.0252 - val_loss: 707977280.0000\n",
      "Epoch 45/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791025792.000 - 0s 58us/step - loss: 788212326.8514 - val_loss: 707976256.0000\n",
      "Epoch 46/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 834492032.000 - 0s 58us/step - loss: 788211366.5290 - val_loss: 707975360.0000\n",
      "Epoch 47/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774216256.000 - 0s 55us/step - loss: 788210439.5768 - val_loss: 707974400.0000\n",
      "Epoch 48/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770258944.000 - 0s 53us/step - loss: 788209532.7758 - val_loss: 707973504.0000\n",
      "Epoch 49/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783668224.000 - 0s 53us/step - loss: 788208630.3275 - val_loss: 707972544.0000\n",
      "Epoch 50/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 803049344.000 - 0s 53us/step - loss: 788207680.9673 - val_loss: 707971648.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773231936.000 - 0s 55us/step - loss: 788206724.1914 - val_loss: 707970624.0000\n",
      "Epoch 52/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 820940544.000 - 0s 58us/step - loss: 788205810.1360 - val_loss: 707969728.0000\n",
      "Epoch 53/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 831059584.000 - 0s 53us/step - loss: 788204881.4106 - val_loss: 707968832.0000\n",
      "Epoch 54/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783631104.000 - 0s 50us/step - loss: 788203943.3350 - val_loss: 707967872.0000\n",
      "Epoch 55/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 745911616.000 - 0s 55us/step - loss: 788202986.5592 - val_loss: 707966912.0000\n",
      "Epoch 56/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 789438016.000 - 0s 50us/step - loss: 788202054.7708 - val_loss: 707965952.0000\n",
      "Epoch 57/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781306432.000 - 0s 53us/step - loss: 788201155.3854 - val_loss: 707964992.0000\n",
      "Epoch 58/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781757824.000 - 0s 53us/step - loss: 788200172.6549 - val_loss: 707964032.0000\n",
      "Epoch 59/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802316608.000 - 0s 50us/step - loss: 788199245.7028 - val_loss: 707963136.0000\n",
      "Epoch 60/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763847488.000 - 0s 53us/step - loss: 788198316.4937 - val_loss: 707962240.0000\n",
      "Epoch 61/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780351936.000 - 0s 50us/step - loss: 788197360.5239 - val_loss: 707961216.0000\n",
      "Epoch 62/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791001088.000 - 0s 50us/step - loss: 788196428.7355 - val_loss: 707960256.0000\n",
      "Epoch 63/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811244736.000 - 0s 55us/step - loss: 788195462.4484 - val_loss: 707959360.0000\n",
      "Epoch 64/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 832537152.000 - 0s 50us/step - loss: 788194561.7733 - val_loss: 707958400.0000\n",
      "Epoch 65/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787512192.000 - 0s 50us/step - loss: 788193666.4181 - val_loss: 707957504.0000\n",
      "Epoch 66/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 844899200.000 - 0s 53us/step - loss: 788192707.5466 - val_loss: 707956480.0000\n",
      "Epoch 67/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793680704.000 - 0s 53us/step - loss: 788191797.6826 - val_loss: 707955648.0000\n",
      "Epoch 68/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779203904.000 - 0s 58us/step - loss: 788190886.8514 - val_loss: 707954688.0000\n",
      "Epoch 69/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794387904.000 - 0s 50us/step - loss: 788189939.9093 - val_loss: 707953728.0000\n",
      "Epoch 70/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806038528.000 - 0s 53us/step - loss: 788188991.3552 - val_loss: 707952704.0000\n",
      "Epoch 71/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796513152.000 - 0s 53us/step - loss: 788188041.3501 - val_loss: 707951808.0000\n",
      "Epoch 72/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807960960.000 - 0s 53us/step - loss: 788187100.3728 - val_loss: 707950848.0000\n",
      "Epoch 73/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787140736.000 - 0s 55us/step - loss: 788186171.1637 - val_loss: 707949888.0000\n",
      "Epoch 74/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763013760.000 - 0s 53us/step - loss: 788185230.3476 - val_loss: 707948992.0000\n",
      "Epoch 75/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 815098624.000 - 0s 53us/step - loss: 788184260.3526 - val_loss: 707948032.0000\n",
      "Epoch 76/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794266240.000 - 0s 53us/step - loss: 788183360.1612 - val_loss: 707947072.0000\n",
      "Epoch 77/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811824768.000 - 0s 50us/step - loss: 788182408.0605 - val_loss: 707946112.0000\n",
      "Epoch 78/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792960512.000 - 0s 55us/step - loss: 788181467.5668 - val_loss: 707945216.0000\n",
      "Epoch 79/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773899776.000 - 0s 53us/step - loss: 788180602.1965 - val_loss: 707944256.0000\n",
      "Epoch 80/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807888000.000 - 0s 53us/step - loss: 788179645.9043 - val_loss: 707943360.0000\n",
      "Epoch 81/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785021696.000 - 0s 60us/step - loss: 788178719.7582 - val_loss: 707942400.0000\n",
      "Epoch 82/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 844198208.000 - 0s 60us/step - loss: 788177773.3804 - val_loss: 707941440.0000\n",
      "Epoch 83/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792146432.000 - 0s 63us/step - loss: 788176869.4005 - val_loss: 707940544.0000\n",
      "Epoch 84/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772067200.000 - 0s 65us/step - loss: 788175954.3778 - val_loss: 707939584.0000\n",
      "Epoch 85/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790564992.000 - 0s 63us/step - loss: 788175049.6725 - val_loss: 707938688.0000\n",
      "Epoch 86/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768781952.000 - 0s 60us/step - loss: 788174141.5819 - val_loss: 707937728.0000\n",
      "Epoch 87/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791534016.000 - 0s 60us/step - loss: 788173167.0730 - val_loss: 707936832.0000\n",
      "Epoch 88/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806341248.000 - 0s 60us/step - loss: 788172254.1461 - val_loss: 707935936.0000\n",
      "Epoch 89/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770999616.000 - 0s 55us/step - loss: 788171352.0202 - val_loss: 707934976.0000\n",
      "Epoch 90/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779749568.000 - 0s 53us/step - loss: 788170366.0655 - val_loss: 707934016.0000\n",
      "Epoch 91/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787642752.000 - 0s 55us/step - loss: 788169508.5945 - val_loss: 707933120.0000\n",
      "Epoch 92/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 826093696.000 - 0s 53us/step - loss: 788168538.4383 - val_loss: 707932160.0000\n",
      "Epoch 93/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814984576.000 - 0s 55us/step - loss: 788167640.8262 - val_loss: 707931200.0000\n",
      "Epoch 94/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 754440320.000 - 0s 53us/step - loss: 788166738.7003 - val_loss: 707930304.0000\n",
      "Epoch 95/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793150720.000 - 0s 55us/step - loss: 788165778.0554 - val_loss: 707929408.0000\n",
      "Epoch 96/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785173248.000 - 0s 55us/step - loss: 788164855.4559 - val_loss: 707928384.0000\n",
      "Epoch 97/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786167936.000 - 0s 55us/step - loss: 788163958.4887 - val_loss: 707927488.0000\n",
      "Epoch 98/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 753814848.000 - 0s 55us/step - loss: 788163019.9295 - val_loss: 707926592.0000\n",
      "Epoch 99/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781225344.000 - 0s 50us/step - loss: 788162082.3375 - val_loss: 707925632.0000\n",
      "Epoch 100/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801581632.000 - 0s 55us/step - loss: 788161189.4005 - val_loss: 707924736.0000\n",
      "Epoch 101/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805973376.000 - 0s 55us/step - loss: 788160268.5743 - val_loss: 707923776.0000\n",
      "Epoch 102/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784705728.000 - 0s 58us/step - loss: 788159304.0605 - val_loss: 707922880.0000\n",
      "Epoch 103/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 775774272.000 - 0s 55us/step - loss: 788158427.8892 - val_loss: 707921856.0000\n",
      "Epoch 104/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 749009280.000 - 0s 58us/step - loss: 788157445.4811 - val_loss: 707920960.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755817728.000 - 0s 55us/step - loss: 788156552.0605 - val_loss: 707920064.0000\n",
      "Epoch 106/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772885952.000 - 0s 55us/step - loss: 788155613.5013 - val_loss: 707919104.0000\n",
      "Epoch 107/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 800967040.000 - 0s 50us/step - loss: 788154661.0781 - val_loss: 707918208.0000\n",
      "Epoch 108/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802868096.000 - 0s 55us/step - loss: 788153811.0227 - val_loss: 707917184.0000\n",
      "Epoch 109/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784240192.000 - 0s 53us/step - loss: 788152831.5164 - val_loss: 707916288.0000\n",
      "Epoch 110/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783307520.000 - 0s 55us/step - loss: 788151876.8363 - val_loss: 707915328.0000\n",
      "Epoch 111/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773573952.000 - 0s 55us/step - loss: 788150978.7406 - val_loss: 707914304.0000\n",
      "Epoch 112/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779710016.000 - 0s 53us/step - loss: 788150011.3249 - val_loss: 707913472.0000\n",
      "Epoch 113/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763405952.000 - 0s 53us/step - loss: 788149086.4685 - val_loss: 707912512.0000\n",
      "Epoch 114/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 823801856.000 - 0s 53us/step - loss: 788148168.2217 - val_loss: 707911552.0000\n",
      "Epoch 115/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 810200832.000 - 0s 58us/step - loss: 788147253.6826 - val_loss: 707910592.0000\n",
      "Epoch 116/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777353088.000 - 0s 55us/step - loss: 788146274.9824 - val_loss: 707909632.0000\n",
      "Epoch 117/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 804015744.000 - 0s 50us/step - loss: 788145383.3350 - val_loss: 707908672.0000\n",
      "Epoch 118/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791609216.000 - 0s 58us/step - loss: 788144417.0479 - val_loss: 707907776.0000\n",
      "Epoch 119/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793680256.000 - 0s 50us/step - loss: 788143488.9673 - val_loss: 707906816.0000\n",
      "Epoch 120/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 835941120.000 - 0s 55us/step - loss: 788142538.4786 - val_loss: 707905920.0000\n",
      "Epoch 121/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795945088.000 - 0s 55us/step - loss: 788141569.7733 - val_loss: 707904960.0000\n",
      "Epoch 122/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796393600.000 - 0s 50us/step - loss: 788140645.8841 - val_loss: 707903936.0000\n",
      "Epoch 123/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772693504.000 - 0s 55us/step - loss: 788139745.3703 - val_loss: 707903040.0000\n",
      "Epoch 124/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809065344.000 - 0s 53us/step - loss: 788138824.0605 - val_loss: 707902144.0000\n",
      "Epoch 125/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763364096.000 - 0s 53us/step - loss: 788137916.4534 - val_loss: 707901184.0000\n",
      "Epoch 126/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802200320.000 - 0s 50us/step - loss: 788136947.7481 - val_loss: 707900224.0000\n",
      "Epoch 127/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784178560.000 - 0s 55us/step - loss: 788135993.5516 - val_loss: 707899328.0000\n",
      "Epoch 128/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783574656.000 - 0s 53us/step - loss: 788135090.7809 - val_loss: 707898368.0000\n",
      "Epoch 129/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807785408.000 - 0s 55us/step - loss: 788134138.6801 - val_loss: 707897344.0000\n",
      "Epoch 130/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 803002880.000 - 0s 55us/step - loss: 788133180.2922 - val_loss: 707896384.0000\n",
      "Epoch 131/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790173120.000 - 0s 53us/step - loss: 788132270.5894 - val_loss: 707895488.0000\n",
      "Epoch 132/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790482816.000 - 0s 55us/step - loss: 788131293.6625 - val_loss: 707894528.0000\n",
      "Epoch 133/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 815854208.000 - 0s 53us/step - loss: 788130411.0428 - val_loss: 707893632.0000\n",
      "Epoch 134/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778483264.000 - 0s 58us/step - loss: 788129429.9244 - val_loss: 707892672.0000\n",
      "Epoch 135/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811082752.000 - 0s 53us/step - loss: 788128534.7305 - val_loss: 707891776.0000\n",
      "Epoch 136/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772774272.000 - 0s 58us/step - loss: 788127615.6776 - val_loss: 707890752.0000\n",
      "Epoch 137/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 761435072.000 - 0s 55us/step - loss: 788126695.8186 - val_loss: 707889920.0000\n",
      "Epoch 138/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774020480.000 - 0s 53us/step - loss: 788125758.5491 - val_loss: 707888896.0000\n",
      "Epoch 139/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780642560.000 - 0s 55us/step - loss: 788124823.6977 - val_loss: 707888000.0000\n",
      "Epoch 140/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777419264.000 - 0s 53us/step - loss: 788123886.2670 - val_loss: 707887040.0000\n",
      "Epoch 141/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786611840.000 - 0s 55us/step - loss: 788122992.3627 - val_loss: 707886144.0000\n",
      "Epoch 142/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770337280.000 - 0s 53us/step - loss: 788122045.9043 - val_loss: 707885248.0000\n",
      "Epoch 143/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755114624.000 - 0s 53us/step - loss: 788121109.6020 - val_loss: 707884224.0000\n",
      "Epoch 144/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799518912.000 - 0s 53us/step - loss: 788120191.0327 - val_loss: 707883264.0000\n",
      "Epoch 145/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 761376640.000 - 0s 58us/step - loss: 788119279.3955 - val_loss: 707882368.0000\n",
      "Epoch 146/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755467264.000 - 0s 55us/step - loss: 788118303.2746 - val_loss: 707881408.0000\n",
      "Epoch 147/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779239680.000 - 0s 53us/step - loss: 788117382.9320 - val_loss: 707880448.0000\n",
      "Epoch 148/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787146944.000 - 0s 53us/step - loss: 788116425.8338 - val_loss: 707879424.0000\n",
      "Epoch 149/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 808810624.000 - 0s 53us/step - loss: 788115475.8287 - val_loss: 707878592.0000\n",
      "Epoch 150/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809491008.000 - 0s 53us/step - loss: 788114542.1058 - val_loss: 707877632.0000\n",
      "Epoch 151/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802072576.000 - 0s 53us/step - loss: 788113596.4534 - val_loss: 707876672.0000\n",
      "Epoch 152/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 775313920.000 - 0s 55us/step - loss: 788112628.7154 - val_loss: 707875712.0000\n",
      "Epoch 153/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 744649216.000 - 0s 53us/step - loss: 788111699.8287 - val_loss: 707874816.0000\n",
      "Epoch 154/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802601216.000 - 0s 55us/step - loss: 788110803.5063 - val_loss: 707873856.0000\n",
      "Epoch 155/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 745557184.000 - 0s 53us/step - loss: 788109859.7884 - val_loss: 707872896.0000\n",
      "Epoch 156/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 810713664.000 - 0s 53us/step - loss: 788108928.0000 - val_loss: 707872000.0000\n",
      "Epoch 157/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793177024.000 - 0s 53us/step - loss: 788107996.6952 - val_loss: 707870976.0000\n",
      "Epoch 158/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - ETA: 0s - loss: 755677888.000 - 0s 55us/step - loss: 788107067.3249 - val_loss: 707870080.0000\n",
      "Epoch 159/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794263232.000 - 0s 55us/step - loss: 788106103.2947 - val_loss: 707869120.0000\n",
      "Epoch 160/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 817542144.000 - 0s 53us/step - loss: 788105179.2443 - val_loss: 707868096.0000\n",
      "Epoch 161/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809032448.000 - 0s 50us/step - loss: 788104201.8338 - val_loss: 707867136.0000\n",
      "Epoch 162/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 751072256.000 - 0s 53us/step - loss: 788103265.2091 - val_loss: 707866304.0000\n",
      "Epoch 163/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806657408.000 - 0s 50us/step - loss: 788102335.8388 - val_loss: 707865344.0000\n",
      "Epoch 164/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786810944.000 - 0s 58us/step - loss: 788101392.4433 - val_loss: 707864320.0000\n",
      "Epoch 165/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780677120.000 - 0s 53us/step - loss: 788100500.9572 - val_loss: 707863424.0000\n",
      "Epoch 166/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778273664.000 - 0s 55us/step - loss: 788099539.6675 - val_loss: 707862464.0000\n",
      "Epoch 167/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 757665216.000 - 0s 55us/step - loss: 788098599.9798 - val_loss: 707861568.0000\n",
      "Epoch 168/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 823246208.000 - 0s 50us/step - loss: 788097690.1159 - val_loss: 707860608.0000\n",
      "Epoch 169/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 753428416.000 - 0s 60us/step - loss: 788096781.5416 - val_loss: 707859712.0000\n",
      "Epoch 170/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776212096.000 - 0s 50us/step - loss: 788095852.6549 - val_loss: 707858688.0000\n",
      "Epoch 171/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 800999872.000 - 0s 58us/step - loss: 788094934.0856 - val_loss: 707857856.0000\n",
      "Epoch 172/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799734016.000 - 0s 53us/step - loss: 788094000.5239 - val_loss: 707856832.0000\n",
      "Epoch 173/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 741414272.000 - 0s 53us/step - loss: 788093038.1058 - val_loss: 707856000.0000\n",
      "Epoch 174/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798207424.000 - 0s 53us/step - loss: 788092160.3224 - val_loss: 707855040.0000\n",
      "Epoch 175/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780511168.000 - 0s 50us/step - loss: 788091236.9169 - val_loss: 707854016.0000\n",
      "Epoch 176/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 749311680.000 - 0s 58us/step - loss: 788090282.3980 - val_loss: 707853120.0000\n",
      "Epoch 177/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773398848.000 - 0s 50us/step - loss: 788089341.7431 - val_loss: 707852160.0000\n",
      "Epoch 178/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793970688.000 - 0s 53us/step - loss: 788088403.0227 - val_loss: 707851264.0000\n",
      "Epoch 179/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 818855744.000 - 0s 55us/step - loss: 788087512.3426 - val_loss: 707850240.0000\n",
      "Epoch 180/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 750732288.000 - 0s 50us/step - loss: 788086581.8438 - val_loss: 707849408.0000\n",
      "Epoch 181/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 749619712.000 - 0s 55us/step - loss: 788085617.9748 - val_loss: 707848448.0000\n",
      "Epoch 182/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 771106432.000 - 0s 55us/step - loss: 788084715.8489 - val_loss: 707847424.0000\n",
      "Epoch 183/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776085120.000 - 0s 58us/step - loss: 788083762.7809 - val_loss: 707846528.0000\n",
      "Epoch 184/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 803040768.000 - 0s 55us/step - loss: 788082801.3300 - val_loss: 707845632.0000\n",
      "Epoch 185/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 753462336.000 - 0s 58us/step - loss: 788081908.5542 - val_loss: 707844672.0000\n",
      "Epoch 186/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 815991872.000 - 0s 53us/step - loss: 788080964.1914 - val_loss: 707843648.0000\n",
      "Epoch 187/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 732236480.000 - 0s 55us/step - loss: 788080028.6952 - val_loss: 707842752.0000\n",
      "Epoch 188/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806483520.000 - 0s 53us/step - loss: 788079062.2469 - val_loss: 707841856.0000\n",
      "Epoch 189/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 808846208.000 - 0s 53us/step - loss: 788078133.8438 - val_loss: 707840832.0000\n",
      "Epoch 190/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 766500736.000 - 0s 55us/step - loss: 788077194.9622 - val_loss: 707839936.0000\n",
      "Epoch 191/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 833130624.000 - 0s 53us/step - loss: 788076307.3451 - val_loss: 707838976.0000\n",
      "Epoch 192/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807064448.000 - 0s 53us/step - loss: 788075312.8463 - val_loss: 707838016.0000\n",
      "Epoch 193/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805912640.000 - 0s 53us/step - loss: 788074387.6675 - val_loss: 707837056.0000\n",
      "Epoch 194/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 813881088.000 - 0s 55us/step - loss: 788073432.9874 - val_loss: 707836160.0000\n",
      "Epoch 195/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 812035328.000 - 0s 55us/step - loss: 788072501.3602 - val_loss: 707835136.0000\n",
      "Epoch 196/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801454208.000 - 0s 55us/step - loss: 788071559.0932 - val_loss: 707834240.0000\n",
      "Epoch 197/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791649344.000 - 0s 55us/step - loss: 788070633.1083 - val_loss: 707833216.0000\n",
      "Epoch 198/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783584256.000 - 0s 58us/step - loss: 788069648.7657 - val_loss: 707832256.0000\n",
      "Epoch 199/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790093760.000 - 0s 55us/step - loss: 788068780.6549 - val_loss: 707831360.0000\n",
      "Epoch 200/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 757005312.000 - 0s 53us/step - loss: 788067839.3552 - val_loss: 707830464.0000\n",
      "Epoch 201/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797222528.000 - 0s 53us/step - loss: 788066889.9950 - val_loss: 707829504.0000\n",
      "Epoch 202/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 758829696.000 - 0s 53us/step - loss: 788065959.3350 - val_loss: 707828544.0000\n",
      "Epoch 203/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 800757376.000 - 0s 53us/step - loss: 788065052.3728 - val_loss: 707827648.0000\n",
      "Epoch 204/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 821518848.000 - 0s 53us/step - loss: 788064117.5214 - val_loss: 707826752.0000\n",
      "Epoch 205/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 747725312.000 - 0s 55us/step - loss: 788063166.8715 - val_loss: 707825728.0000\n",
      "Epoch 206/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780973632.000 - 0s 58us/step - loss: 788062237.3401 - val_loss: 707824832.0000\n",
      "Epoch 207/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782144640.000 - 0s 58us/step - loss: 788061346.3375 - val_loss: 707823936.0000\n",
      "Epoch 208/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770314752.000 - 0s 55us/step - loss: 788060386.6599 - val_loss: 707823040.0000\n",
      "Epoch 209/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762983168.000 - 0s 55us/step - loss: 788059461.9647 - val_loss: 707822016.0000\n",
      "Epoch 210/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805744512.000 - 0s 55us/step - loss: 788058551.4559 - val_loss: 707821056.0000\n",
      "Epoch 211/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 732510784.000 - 0s 50us/step - loss: 788057648.0403 - val_loss: 707820096.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772606464.000 - 0s 53us/step - loss: 788056653.8640 - val_loss: 707819200.0000\n",
      "Epoch 213/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814428672.000 - 0s 50us/step - loss: 788055724.0101 - val_loss: 707818240.0000\n",
      "Epoch 214/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785549184.000 - 0s 53us/step - loss: 788054785.1285 - val_loss: 707817280.0000\n",
      "Epoch 215/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770431424.000 - 0s 55us/step - loss: 788053836.2519 - val_loss: 707816384.0000\n",
      "Epoch 216/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755819392.000 - 0s 50us/step - loss: 788052911.5567 - val_loss: 707815488.0000\n",
      "Epoch 217/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793929728.000 - 0s 55us/step - loss: 788051972.1914 - val_loss: 707814464.0000\n",
      "Epoch 218/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 760736832.000 - 0s 50us/step - loss: 788051063.1335 - val_loss: 707813504.0000\n",
      "Epoch 219/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 804408896.000 - 0s 50us/step - loss: 788050146.6599 - val_loss: 707812608.0000\n",
      "Epoch 220/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780957376.000 - 0s 53us/step - loss: 788049233.5718 - val_loss: 707811648.0000\n",
      "Epoch 221/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 789633216.000 - 0s 50us/step - loss: 788048289.3703 - val_loss: 707810752.0000\n",
      "Epoch 222/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801739776.000 - 0s 53us/step - loss: 788047443.9899 - val_loss: 707809856.0000\n",
      "Epoch 223/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792625472.000 - 0s 50us/step - loss: 788046492.3728 - val_loss: 707808896.0000\n",
      "Epoch 224/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777677184.000 - 0s 55us/step - loss: 788045544.4635 - val_loss: 707808000.0000\n",
      "Epoch 225/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 733214528.000 - 0s 55us/step - loss: 788044585.9144 - val_loss: 707807040.0000\n",
      "Epoch 226/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784596032.000 - 0s 50us/step - loss: 788043698.9421 - val_loss: 707806080.0000\n",
      "Epoch 227/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762297728.000 - 0s 55us/step - loss: 788042795.3652 - val_loss: 707805120.0000\n",
      "Epoch 228/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 836149120.000 - 0s 50us/step - loss: 788041859.0630 - val_loss: 707804160.0000\n",
      "Epoch 229/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 757201728.000 - 0s 58us/step - loss: 788040924.0504 - val_loss: 707803264.0000\n",
      "Epoch 230/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783144512.000 - 0s 53us/step - loss: 788039966.6297 - val_loss: 707802368.0000\n",
      "Epoch 231/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809628992.000 - 0s 58us/step - loss: 788039060.6348 - val_loss: 707801408.0000\n",
      "Epoch 232/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779279104.000 - 0s 53us/step - loss: 788038133.3602 - val_loss: 707800512.0000\n",
      "Epoch 233/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777475712.000 - 0s 53us/step - loss: 788037231.7179 - val_loss: 707799488.0000\n",
      "Epoch 234/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756314880.000 - 0s 58us/step - loss: 788036253.6625 - val_loss: 707798592.0000\n",
      "Epoch 235/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783911936.000 - 0s 50us/step - loss: 788035324.4534 - val_loss: 707797632.0000\n",
      "Epoch 236/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768762240.000 - 0s 55us/step - loss: 788034377.0277 - val_loss: 707796736.0000\n",
      "Epoch 237/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763823744.000 - 0s 53us/step - loss: 788033464.1008 - val_loss: 707795712.0000\n",
      "Epoch 238/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778995840.000 - 0s 55us/step - loss: 788032513.7733 - val_loss: 707794816.0000\n",
      "Epoch 239/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 818357824.000 - 0s 55us/step - loss: 788031595.8489 - val_loss: 707793856.0000\n",
      "Epoch 240/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 764632448.000 - 0s 55us/step - loss: 788030677.2796 - val_loss: 707792960.0000\n",
      "Epoch 241/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772270208.000 - 0s 50us/step - loss: 788029782.0856 - val_loss: 707792064.0000\n",
      "Epoch 242/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 745012224.000 - 0s 50us/step - loss: 788028828.0504 - val_loss: 707791104.0000\n",
      "Epoch 243/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774771072.000 - 0s 53us/step - loss: 788027913.6725 - val_loss: 707790208.0000\n",
      "Epoch 244/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 821291968.000 - 0s 53us/step - loss: 788026991.5567 - val_loss: 707789248.0000\n",
      "Epoch 245/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 823802368.000 - 0s 55us/step - loss: 788026047.1940 - val_loss: 707788288.0000\n",
      "Epoch 246/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809062464.000 - 0s 58us/step - loss: 788025111.2141 - val_loss: 707787328.0000\n",
      "Epoch 247/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 764567424.000 - 0s 58us/step - loss: 788024183.6171 - val_loss: 707786496.0000\n",
      "Epoch 248/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811767808.000 - 0s 55us/step - loss: 788023277.6222 - val_loss: 707785472.0000\n",
      "Epoch 249/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 808693248.000 - 0s 55us/step - loss: 788022342.1259 - val_loss: 707784512.0000\n",
      "Epoch 250/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763668864.000 - 0s 53us/step - loss: 788021412.9169 - val_loss: 707783616.0000\n",
      "Epoch 251/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 759722240.000 - 0s 50us/step - loss: 788020475.8086 - val_loss: 707782720.0000\n",
      "Epoch 252/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769215616.000 - 0s 55us/step - loss: 788019557.5617 - val_loss: 707781696.0000\n",
      "Epoch 253/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785806528.000 - 0s 55us/step - loss: 788018684.9370 - val_loss: 707780736.0000\n",
      "Epoch 254/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772863360.000 - 0s 53us/step - loss: 788017755.5668 - val_loss: 707779840.0000\n",
      "Epoch 255/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792212864.000 - 0s 55us/step - loss: 788016832.4836 - val_loss: 707778944.0000\n",
      "Epoch 256/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787248832.000 - 0s 53us/step - loss: 788015890.5390 - val_loss: 707777984.0000\n",
      "Epoch 257/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767135936.000 - 0s 53us/step - loss: 788014949.5617 - val_loss: 707777088.0000\n",
      "Epoch 258/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792064000.000 - 0s 58us/step - loss: 788014001.0076 - val_loss: 707776128.0000\n",
      "Epoch 259/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 841987200.000 - 0s 53us/step - loss: 788013096.7859 - val_loss: 707775168.0000\n",
      "Epoch 260/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 846002176.000 - 0s 55us/step - loss: 788012165.1587 - val_loss: 707774336.0000\n",
      "Epoch 261/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792355520.000 - 0s 53us/step - loss: 788011250.1360 - val_loss: 707773376.0000\n",
      "Epoch 262/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783886528.000 - 0s 50us/step - loss: 788010352.0403 - val_loss: 707772416.0000\n",
      "Epoch 263/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772716480.000 - 0s 55us/step - loss: 788009419.6071 - val_loss: 707771456.0000\n",
      "Epoch 264/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798557248.000 - 0s 58us/step - loss: 788008469.9244 - val_loss: 707770496.0000\n",
      "Epoch 265/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - ETA: 0s - loss: 777277504.000 - 0s 58us/step - loss: 788007514.9219 - val_loss: 707769600.0000\n",
      "Epoch 266/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786223104.000 - 0s 50us/step - loss: 788006581.1990 - val_loss: 707768640.0000\n",
      "Epoch 267/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794624064.000 - 0s 55us/step - loss: 788005645.8640 - val_loss: 707767680.0000\n",
      "Epoch 268/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776818880.000 - 0s 53us/step - loss: 788004708.4332 - val_loss: 707766720.0000\n",
      "Epoch 269/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756403712.000 - 0s 50us/step - loss: 788003856.2821 - val_loss: 707765824.0000\n",
      "Epoch 270/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 775110912.000 - 0s 58us/step - loss: 788002858.0756 - val_loss: 707764928.0000\n",
      "Epoch 271/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782180992.000 - 0s 53us/step - loss: 788001963.8489 - val_loss: 707763968.0000\n",
      "Epoch 272/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797735040.000 - 0s 53us/step - loss: 788001074.7809 - val_loss: 707763008.0000\n",
      "Epoch 273/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 824648576.000 - 0s 55us/step - loss: 788000159.1134 - val_loss: 707762112.0000\n",
      "Epoch 274/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786374656.000 - 0s 50us/step - loss: 787999221.3602 - val_loss: 707761152.0000\n",
      "Epoch 275/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779015040.000 - 0s 58us/step - loss: 787998290.2166 - val_loss: 707760320.0000\n",
      "Epoch 276/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787933184.000 - 0s 50us/step - loss: 787997384.8665 - val_loss: 707759360.0000\n",
      "Epoch 277/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809622784.000 - 0s 53us/step - loss: 787996429.5416 - val_loss: 707758400.0000\n",
      "Epoch 278/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779787072.000 - 0s 55us/step - loss: 787995532.5743 - val_loss: 707757504.0000\n",
      "Epoch 279/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 846490624.000 - 0s 50us/step - loss: 787994601.5919 - val_loss: 707756544.0000\n",
      "Epoch 280/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 789779456.000 - 0s 58us/step - loss: 787993645.6222 - val_loss: 707755584.0000\n",
      "Epoch 281/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 788662528.000 - 0s 50us/step - loss: 787992767.0327 - val_loss: 707754688.0000\n",
      "Epoch 282/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811737536.000 - 0s 55us/step - loss: 787991821.0579 - val_loss: 707753728.0000\n",
      "Epoch 283/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806107648.000 - 0s 53us/step - loss: 787990898.4584 - val_loss: 707752896.0000\n",
      "Epoch 284/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 823527040.000 - 0s 55us/step - loss: 787989970.2166 - val_loss: 707751872.0000\n",
      "Epoch 285/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772801280.000 - 0s 55us/step - loss: 787989000.7053 - val_loss: 707750912.0000\n",
      "Epoch 286/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807231488.000 - 0s 50us/step - loss: 787988139.3652 - val_loss: 707749952.0000\n",
      "Epoch 287/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 827277248.000 - 0s 53us/step - loss: 787987165.5013 - val_loss: 707749056.0000\n",
      "Epoch 288/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 713890240.000 - 0s 50us/step - loss: 787986248.7053 - val_loss: 707748096.0000\n",
      "Epoch 289/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768438912.000 - 0s 55us/step - loss: 787985276.2922 - val_loss: 707747136.0000\n",
      "Epoch 290/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781727104.000 - 0s 53us/step - loss: 787984353.8539 - val_loss: 707746176.0000\n",
      "Epoch 291/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778116992.000 - 0s 58us/step - loss: 787983408.5239 - val_loss: 707745216.0000\n",
      "Epoch 292/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786518656.000 - 0s 55us/step - loss: 787982444.6549 - val_loss: 707744320.0000\n",
      "Epoch 293/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777388352.000 - 0s 55us/step - loss: 787981507.7078 - val_loss: 707743296.0000\n",
      "Epoch 294/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 826206912.000 - 0s 58us/step - loss: 787980607.0327 - val_loss: 707742464.0000\n",
      "Epoch 295/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776700864.000 - 0s 53us/step - loss: 787979682.3375 - val_loss: 707741440.0000\n",
      "Epoch 296/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762302208.000 - 0s 53us/step - loss: 787978768.9270 - val_loss: 707740544.0000\n",
      "Epoch 297/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 734057472.000 - 0s 53us/step - loss: 787977878.5693 - val_loss: 707739648.0000\n",
      "Epoch 298/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 848372224.000 - 0s 58us/step - loss: 787976925.5013 - val_loss: 707738688.0000\n",
      "Epoch 299/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755098752.000 - 0s 53us/step - loss: 787976000.3224 - val_loss: 707737792.0000\n",
      "Epoch 300/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 803889920.000 - 0s 55us/step - loss: 787975090.9421 - val_loss: 707736832.0000\n",
      "Epoch 301/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802168256.000 - 0s 55us/step - loss: 787974174.3073 - val_loss: 707735808.0000\n",
      "Epoch 302/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 747966976.000 - 0s 55us/step - loss: 787973168.6851 - val_loss: 707734976.0000\n",
      "Epoch 303/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 808130432.000 - 0s 55us/step - loss: 787972330.3980 - val_loss: 707734080.0000\n",
      "Epoch 304/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795299968.000 - 0s 55us/step - loss: 787971385.8741 - val_loss: 707733056.0000\n",
      "Epoch 305/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805472384.000 - 0s 55us/step - loss: 787970485.8438 - val_loss: 707732096.0000\n",
      "Epoch 306/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780342784.000 - 0s 53us/step - loss: 787969550.6700 - val_loss: 707731200.0000\n",
      "Epoch 307/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 822056704.000 - 0s 55us/step - loss: 787968578.2569 - val_loss: 707730240.0000\n",
      "Epoch 308/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794601728.000 - 0s 53us/step - loss: 787967617.4509 - val_loss: 707729280.0000\n",
      "Epoch 309/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756381632.000 - 0s 58us/step - loss: 787966680.0202 - val_loss: 707728384.0000\n",
      "Epoch 310/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783784832.000 - 0s 53us/step - loss: 787965766.4484 - val_loss: 707727424.0000\n",
      "Epoch 311/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 752798976.000 - 0s 55us/step - loss: 787964806.4484 - val_loss: 707726464.0000\n",
      "Epoch 312/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780821120.000 - 0s 53us/step - loss: 787963877.2393 - val_loss: 707725504.0000\n",
      "Epoch 313/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784791424.000 - 0s 53us/step - loss: 787962939.8086 - val_loss: 707724544.0000\n",
      "Epoch 314/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 812063488.000 - 0s 50us/step - loss: 787962012.6952 - val_loss: 707723648.0000\n",
      "Epoch 315/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783276160.000 - 0s 50us/step - loss: 787961064.7859 - val_loss: 707722688.0000\n",
      "Epoch 316/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 815723648.000 - 0s 53us/step - loss: 787960158.3073 - val_loss: 707721792.0000\n",
      "Epoch 317/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 855391616.000 - 0s 53us/step - loss: 787959189.4408 - val_loss: 707720768.0000\n",
      "Epoch 318/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 810999168.000 - 0s 55us/step - loss: 787958253.6222 - val_loss: 707719808.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774827328.000 - 0s 53us/step - loss: 787957312.8060 - val_loss: 707718912.0000\n",
      "Epoch 320/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799636032.000 - 0s 50us/step - loss: 787956398.2670 - val_loss: 707717952.0000\n",
      "Epoch 321/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 810080512.000 - 0s 58us/step - loss: 787955458.2569 - val_loss: 707717056.0000\n",
      "Epoch 322/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768033024.000 - 0s 50us/step - loss: 787954505.8338 - val_loss: 707716096.0000\n",
      "Epoch 323/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 835755648.000 - 0s 53us/step - loss: 787953600.0000 - val_loss: 707715072.0000\n",
      "Epoch 324/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 800313536.000 - 0s 55us/step - loss: 787952675.4660 - val_loss: 707714112.0000\n",
      "Epoch 325/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 789354624.000 - 0s 50us/step - loss: 787951704.6650 - val_loss: 707713280.0000\n",
      "Epoch 326/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 739094464.000 - 0s 55us/step - loss: 787950760.6247 - val_loss: 707712256.0000\n",
      "Epoch 327/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774406400.000 - 0s 53us/step - loss: 787949884.4534 - val_loss: 707711360.0000\n",
      "Epoch 328/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769120704.000 - 0s 58us/step - loss: 787948941.8640 - val_loss: 707710464.0000\n",
      "Epoch 329/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 810217536.000 - 0s 53us/step - loss: 787948020.5542 - val_loss: 707709504.0000\n",
      "Epoch 330/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772427264.000 - 0s 55us/step - loss: 787947106.8212 - val_loss: 707708544.0000\n",
      "Epoch 331/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 765992384.000 - 0s 53us/step - loss: 787946161.6524 - val_loss: 707707648.0000\n",
      "Epoch 332/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770088448.000 - 0s 50us/step - loss: 787945208.9068 - val_loss: 707706624.0000\n",
      "Epoch 333/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 789399552.000 - 0s 55us/step - loss: 787944239.3955 - val_loss: 707705664.0000\n",
      "Epoch 334/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 748850304.000 - 0s 53us/step - loss: 787943268.5945 - val_loss: 707704768.0000\n",
      "Epoch 335/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791655936.000 - 0s 58us/step - loss: 787942391.7783 - val_loss: 707703808.0000\n",
      "Epoch 336/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 804953216.000 - 0s 53us/step - loss: 787941427.1033 - val_loss: 707702848.0000\n",
      "Epoch 337/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 757097728.000 - 0s 50us/step - loss: 787940488.5441 - val_loss: 707701824.0000\n",
      "Epoch 338/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790492288.000 - 0s 53us/step - loss: 787939536.1209 - val_loss: 707700928.0000\n",
      "Epoch 339/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 754236352.000 - 0s 50us/step - loss: 787938637.2191 - val_loss: 707699968.0000\n",
      "Epoch 340/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763011776.000 - 0s 55us/step - loss: 787937651.2645 - val_loss: 707699072.0000\n",
      "Epoch 341/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790932864.000 - 0s 53us/step - loss: 787936746.0756 - val_loss: 707698176.0000\n",
      "Epoch 342/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769836352.000 - 0s 48us/step - loss: 787935835.5668 - val_loss: 707697152.0000\n",
      "Epoch 343/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792086592.000 - 0s 53us/step - loss: 787934860.7355 - val_loss: 707696256.0000\n",
      "Epoch 344/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 835652672.000 - 0s 53us/step - loss: 787933981.1788 - val_loss: 707695360.0000\n",
      "Epoch 345/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814884032.000 - 0s 53us/step - loss: 787933008.4433 - val_loss: 707694336.0000\n",
      "Epoch 346/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778304768.000 - 0s 55us/step - loss: 787932083.2645 - val_loss: 707693376.0000\n",
      "Epoch 347/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778136832.000 - 0s 50us/step - loss: 787931141.1587 - val_loss: 707692480.0000\n",
      "Epoch 348/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 825946880.000 - 0s 55us/step - loss: 787930222.5894 - val_loss: 707691584.0000\n",
      "Epoch 349/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 742070912.000 - 0s 50us/step - loss: 787929333.1990 - val_loss: 707690624.0000\n",
      "Epoch 350/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797946368.000 - 0s 55us/step - loss: 787928383.1940 - val_loss: 707689600.0000\n",
      "Epoch 351/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 743464320.000 - 0s 55us/step - loss: 787927446.5693 - val_loss: 707688704.0000\n",
      "Epoch 352/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798849728.000 - 0s 65us/step - loss: 787926557.6625 - val_loss: 707687808.0000\n",
      "Epoch 353/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763437824.000 - 0s 50us/step - loss: 787925574.2872 - val_loss: 707686848.0000\n",
      "Epoch 354/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801936000.000 - 0s 55us/step - loss: 787924625.4106 - val_loss: 707685824.0000\n",
      "Epoch 355/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 741066240.000 - 0s 53us/step - loss: 787923681.3703 - val_loss: 707684928.0000\n",
      "Epoch 356/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 812395264.000 - 0s 53us/step - loss: 787922716.6952 - val_loss: 707683904.0000\n",
      "Epoch 357/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 829449600.000 - 0s 53us/step - loss: 787921778.4584 - val_loss: 707683008.0000\n",
      "Epoch 358/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 800393984.000 - 0s 50us/step - loss: 787920895.3552 - val_loss: 707682112.0000\n",
      "Epoch 359/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811204544.000 - 0s 55us/step - loss: 787919937.2897 - val_loss: 707681152.0000\n",
      "Epoch 360/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797033280.000 - 0s 53us/step - loss: 787919012.9169 - val_loss: 707680192.0000\n",
      "Epoch 361/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 825267712.000 - 0s 55us/step - loss: 787918079.6776 - val_loss: 707679232.0000\n",
      "Epoch 362/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801774144.000 - 0s 55us/step - loss: 787917121.9345 - val_loss: 707678272.0000\n",
      "Epoch 363/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809995840.000 - 0s 55us/step - loss: 787916191.2746 - val_loss: 707677440.0000\n",
      "Epoch 364/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 831128768.000 - 0s 53us/step - loss: 787915287.6977 - val_loss: 707676480.0000\n",
      "Epoch 365/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777765376.000 - 0s 55us/step - loss: 787914386.2166 - val_loss: 707675520.0000\n",
      "Epoch 366/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767094400.000 - 0s 50us/step - loss: 787913476.9975 - val_loss: 707674688.0000\n",
      "Epoch 367/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796852672.000 - 0s 48us/step - loss: 787912538.5995 - val_loss: 707673664.0000\n",
      "Epoch 368/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806958464.000 - 0s 53us/step - loss: 787911576.5038 - val_loss: 707672704.0000\n",
      "Epoch 369/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774103296.000 - 0s 50us/step - loss: 787910633.4307 - val_loss: 707671808.0000\n",
      "Epoch 370/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778541120.000 - 0s 53us/step - loss: 787909690.6801 - val_loss: 707670784.0000\n",
      "Epoch 371/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 803335296.000 - 0s 55us/step - loss: 787908739.8690 - val_loss: 707669888.0000\n",
      "Epoch 372/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - ETA: 0s - loss: 807350976.000 - 0s 55us/step - loss: 787907819.0428 - val_loss: 707668928.0000\n",
      "Epoch 373/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793618752.000 - 0s 53us/step - loss: 787906861.2997 - val_loss: 707667904.0000\n",
      "Epoch 374/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 747908736.000 - 0s 48us/step - loss: 787905879.3753 - val_loss: 707666944.0000\n",
      "Epoch 375/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 821923456.000 - 0s 50us/step - loss: 787904935.4962 - val_loss: 707666048.0000\n",
      "Epoch 376/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790075776.000 - 0s 53us/step - loss: 787903991.6171 - val_loss: 707665088.0000\n",
      "Epoch 377/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 826118400.000 - 0s 53us/step - loss: 787903087.3955 - val_loss: 707664128.0000\n",
      "Epoch 378/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 827061248.000 - 0s 55us/step - loss: 787902116.7557 - val_loss: 707663168.0000\n",
      "Epoch 379/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 789220864.000 - 0s 53us/step - loss: 787901189.3199 - val_loss: 707662208.0000\n",
      "Epoch 380/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 824123008.000 - 0s 50us/step - loss: 787900265.7531 - val_loss: 707661248.0000\n",
      "Epoch 381/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 775950336.000 - 0s 55us/step - loss: 787899296.7254 - val_loss: 707660352.0000\n",
      "Epoch 382/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 833893952.000 - 0s 50us/step - loss: 787898408.7859 - val_loss: 707659392.0000\n",
      "Epoch 383/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755442752.000 - 0s 55us/step - loss: 787897469.9043 - val_loss: 707658432.0000\n",
      "Epoch 384/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773713216.000 - 0s 53us/step - loss: 787896500.5542 - val_loss: 707657536.0000\n",
      "Epoch 385/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774867328.000 - 0s 50us/step - loss: 787895541.3602 - val_loss: 707656512.0000\n",
      "Epoch 386/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 819113536.000 - 0s 55us/step - loss: 787894650.6801 - val_loss: 707655616.0000\n",
      "Epoch 387/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 749412672.000 - 0s 50us/step - loss: 787893733.8841 - val_loss: 707654720.0000\n",
      "Epoch 388/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769045632.000 - 0s 55us/step - loss: 787892786.6196 - val_loss: 707653696.0000\n",
      "Epoch 389/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 816321280.000 - 0s 53us/step - loss: 787891863.2141 - val_loss: 707652800.0000\n",
      "Epoch 390/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790795136.000 - 0s 58us/step - loss: 787890928.3627 - val_loss: 707651840.0000\n",
      "Epoch 391/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 752131712.000 - 0s 55us/step - loss: 787889954.6599 - val_loss: 707650944.0000\n",
      "Epoch 392/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763679360.000 - 0s 48us/step - loss: 787889044.4736 - val_loss: 707649984.0000\n",
      "Epoch 393/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806834560.000 - 0s 55us/step - loss: 787888112.0403 - val_loss: 707648960.0000\n",
      "Epoch 394/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 750829696.000 - 0s 53us/step - loss: 787887137.3703 - val_loss: 707648064.0000\n",
      "Epoch 395/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793153728.000 - 0s 58us/step - loss: 787886211.0630 - val_loss: 707647168.0000\n",
      "Epoch 396/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 833212096.000 - 0s 53us/step - loss: 787885297.6524 - val_loss: 707646208.0000\n",
      "Epoch 397/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 812370304.000 - 0s 55us/step - loss: 787884410.3577 - val_loss: 707645248.0000\n",
      "Epoch 398/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799162368.000 - 0s 58us/step - loss: 787883453.7431 - val_loss: 707644352.0000\n",
      "Epoch 399/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 747224704.000 - 0s 48us/step - loss: 787882519.8589 - val_loss: 707643392.0000\n",
      "Epoch 400/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780863232.000 - 0s 55us/step - loss: 787881579.2040 - val_loss: 707642432.0000\n",
      "Epoch 401/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784788096.000 - 0s 50us/step - loss: 787880648.3829 - val_loss: 707641472.0000\n",
      "Epoch 402/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795728320.000 - 0s 58us/step - loss: 787879704.0202 - val_loss: 707640576.0000\n",
      "Epoch 403/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782887808.000 - 0s 53us/step - loss: 787878775.6171 - val_loss: 707639616.0000\n",
      "Epoch 404/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755573376.000 - 0s 58us/step - loss: 787877847.6977 - val_loss: 707638720.0000\n",
      "Epoch 405/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 812439296.000 - 0s 58us/step - loss: 787876928.4836 - val_loss: 707637760.0000\n",
      "Epoch 406/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 817854592.000 - 0s 55us/step - loss: 787875986.7003 - val_loss: 707636800.0000\n",
      "Epoch 407/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756352384.000 - 0s 53us/step - loss: 787875101.5013 - val_loss: 707635840.0000\n",
      "Epoch 408/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779796288.000 - 0s 55us/step - loss: 787874116.6751 - val_loss: 707634944.0000\n",
      "Epoch 409/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762179072.000 - 0s 55us/step - loss: 787873244.5340 - val_loss: 707634048.0000\n",
      "Epoch 410/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802552320.000 - 0s 53us/step - loss: 787872320.1612 - val_loss: 707633088.0000\n",
      "Epoch 411/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801246592.000 - 0s 53us/step - loss: 787871388.5340 - val_loss: 707632128.0000\n",
      "Epoch 412/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801014272.000 - 0s 55us/step - loss: 787870475.4458 - val_loss: 707631168.0000\n",
      "Epoch 413/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768455168.000 - 0s 55us/step - loss: 787869542.0453 - val_loss: 707630272.0000\n",
      "Epoch 414/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776423360.000 - 0s 55us/step - loss: 787868539.9698 - val_loss: 707629312.0000\n",
      "Epoch 415/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777781504.000 - 0s 53us/step - loss: 787867648.3224 - val_loss: 707628288.0000\n",
      "Epoch 416/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782898880.000 - 0s 50us/step - loss: 787866744.2620 - val_loss: 707627456.0000\n",
      "Epoch 417/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 765870848.000 - 0s 55us/step - loss: 787865796.9975 - val_loss: 707626496.0000\n",
      "Epoch 418/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 750892672.000 - 0s 53us/step - loss: 787864852.6348 - val_loss: 707625536.0000\n",
      "Epoch 419/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779442688.000 - 0s 58us/step - loss: 787863948.4131 - val_loss: 707624576.0000\n",
      "Epoch 420/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807494336.000 - 0s 55us/step - loss: 787862998.0856 - val_loss: 707623680.0000\n",
      "Epoch 421/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767601024.000 - 0s 55us/step - loss: 787862046.1461 - val_loss: 707622720.0000\n",
      "Epoch 422/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 817099648.000 - 0s 55us/step - loss: 787861109.1990 - val_loss: 707621824.0000\n",
      "Epoch 423/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 843507840.000 - 0s 58us/step - loss: 787860209.4912 - val_loss: 707620800.0000\n",
      "Epoch 424/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776835968.000 - 0s 55us/step - loss: 787859259.4861 - val_loss: 707619904.0000\n",
      "Epoch 425/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809678016.000 - 0s 50us/step - loss: 787858289.1688 - val_loss: 707618944.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780072256.000 - 0s 53us/step - loss: 787857351.0932 - val_loss: 707618048.0000\n",
      "Epoch 427/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 760459008.000 - 0s 53us/step - loss: 787856438.6499 - val_loss: 707617024.0000\n",
      "Epoch 428/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806988352.000 - 0s 58us/step - loss: 787855539.9093 - val_loss: 707616128.0000\n",
      "Epoch 429/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755149440.000 - 0s 53us/step - loss: 787854576.5239 - val_loss: 707615168.0000\n",
      "Epoch 430/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763916096.000 - 0s 53us/step - loss: 787853647.9597 - val_loss: 707614144.0000\n",
      "Epoch 431/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781175808.000 - 0s 53us/step - loss: 787852701.3401 - val_loss: 707613248.0000\n",
      "Epoch 432/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802734080.000 - 0s 50us/step - loss: 787851779.3854 - val_loss: 707612288.0000\n",
      "Epoch 433/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776423168.000 - 0s 53us/step - loss: 787850849.5315 - val_loss: 707611392.0000\n",
      "Epoch 434/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 845359296.000 - 0s 53us/step - loss: 787849912.4232 - val_loss: 707610496.0000\n",
      "Epoch 435/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 816742528.000 - 0s 55us/step - loss: 787848978.2166 - val_loss: 707609536.0000\n",
      "Epoch 436/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 766743424.000 - 0s 53us/step - loss: 787848053.6826 - val_loss: 707608640.0000\n",
      "Epoch 437/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777972352.000 - 0s 53us/step - loss: 787847105.1285 - val_loss: 707607616.0000\n",
      "Epoch 438/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805510400.000 - 0s 58us/step - loss: 787846190.4282 - val_loss: 707606720.0000\n",
      "Epoch 439/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756923776.000 - 0s 50us/step - loss: 787845261.3804 - val_loss: 707605760.0000\n",
      "Epoch 440/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776465152.000 - 0s 55us/step - loss: 787844392.1411 - val_loss: 707604928.0000\n",
      "Epoch 441/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 764178048.000 - 0s 50us/step - loss: 787843423.5970 - val_loss: 707604032.0000\n",
      "Epoch 442/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763942656.000 - 0s 50us/step - loss: 787842515.3451 - val_loss: 707603008.0000\n",
      "Epoch 443/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 766178176.000 - 0s 55us/step - loss: 787841566.1461 - val_loss: 707602048.0000\n",
      "Epoch 444/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 788922624.000 - 0s 53us/step - loss: 787840652.8967 - val_loss: 707601152.0000\n",
      "Epoch 445/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801874944.000 - 0s 58us/step - loss: 787839722.2368 - val_loss: 707600256.0000\n",
      "Epoch 446/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786708992.000 - 0s 53us/step - loss: 787838831.8791 - val_loss: 707599296.0000\n",
      "Epoch 447/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 851940096.000 - 0s 53us/step - loss: 787837871.0730 - val_loss: 707598272.0000\n",
      "Epoch 448/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805791360.000 - 0s 53us/step - loss: 787836915.5869 - val_loss: 707597376.0000\n",
      "Epoch 449/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790075264.000 - 0s 50us/step - loss: 787836014.1058 - val_loss: 707596480.0000\n",
      "Epoch 450/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807511680.000 - 0s 55us/step - loss: 787835080.5441 - val_loss: 707595456.0000\n",
      "Epoch 451/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 752526528.000 - 0s 53us/step - loss: 787834104.5844 - val_loss: 707594496.0000\n",
      "Epoch 452/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798637888.000 - 0s 55us/step - loss: 787833224.7053 - val_loss: 707593600.0000\n",
      "Epoch 453/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793960384.000 - 0s 53us/step - loss: 787832308.0705 - val_loss: 707592704.0000\n",
      "Epoch 454/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 815039552.000 - 0s 53us/step - loss: 787831432.2217 - val_loss: 707591744.0000\n",
      "Epoch 455/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 732713856.000 - 0s 55us/step - loss: 787830435.4660 - val_loss: 707590912.0000\n",
      "Epoch 456/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 761133760.000 - 0s 53us/step - loss: 787829527.2141 - val_loss: 707589952.0000\n",
      "Epoch 457/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792696192.000 - 0s 58us/step - loss: 787828629.2796 - val_loss: 707589056.0000\n",
      "Epoch 458/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 872438592.000 - 0s 55us/step - loss: 787827734.8917 - val_loss: 707588096.0000\n",
      "Epoch 459/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 748848384.000 - 0s 55us/step - loss: 787826799.8791 - val_loss: 707587136.0000\n",
      "Epoch 460/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778933504.000 - 0s 55us/step - loss: 787825875.9899 - val_loss: 707586176.0000\n",
      "Epoch 461/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 804295040.000 - 0s 55us/step - loss: 787824947.9093 - val_loss: 707585280.0000\n",
      "Epoch 462/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769197248.000 - 0s 58us/step - loss: 787824048.8463 - val_loss: 707584384.0000\n",
      "Epoch 463/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805191296.000 - 0s 53us/step - loss: 787823140.9169 - val_loss: 707583424.0000\n",
      "Epoch 464/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785042560.000 - 0s 53us/step - loss: 787822214.6096 - val_loss: 707582528.0000\n",
      "Epoch 465/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 865617280.000 - 0s 53us/step - loss: 787821316.5139 - val_loss: 707581568.0000\n",
      "Epoch 466/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795805312.000 - 0s 55us/step - loss: 787820380.6952 - val_loss: 707580672.0000\n",
      "Epoch 467/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784333568.000 - 0s 53us/step - loss: 787819488.0806 - val_loss: 707579776.0000\n",
      "Epoch 468/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779505920.000 - 0s 55us/step - loss: 787818563.2242 - val_loss: 707578816.0000\n",
      "Epoch 469/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805630976.000 - 0s 58us/step - loss: 787817616.6045 - val_loss: 707577856.0000\n",
      "Epoch 470/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 758159168.000 - 0s 53us/step - loss: 787816678.3678 - val_loss: 707576896.0000\n",
      "Epoch 471/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787304320.000 - 0s 53us/step - loss: 787815778.3375 - val_loss: 707576000.0000\n",
      "Epoch 472/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769696448.000 - 0s 53us/step - loss: 787814833.1688 - val_loss: 707575040.0000\n",
      "Epoch 473/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786512384.000 - 0s 55us/step - loss: 787813915.7280 - val_loss: 707574208.0000\n",
      "Epoch 474/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768418304.000 - 0s 55us/step - loss: 787812997.3199 - val_loss: 707573184.0000\n",
      "Epoch 475/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 815366912.000 - 0s 53us/step - loss: 787812049.5718 - val_loss: 707572224.0000\n",
      "Epoch 476/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806658560.000 - 0s 50us/step - loss: 787811185.1688 - val_loss: 707571456.0000\n",
      "Epoch 477/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796454720.000 - 0s 50us/step - loss: 787810221.7834 - val_loss: 707570432.0000\n",
      "Epoch 478/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 727631680.000 - 0s 53us/step - loss: 787809312.7254 - val_loss: 707569472.0000\n",
      "Epoch 479/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - ETA: 0s - loss: 784244224.000 - 0s 55us/step - loss: 787808415.7582 - val_loss: 707568576.0000\n",
      "Epoch 480/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 765682560.000 - 0s 55us/step - loss: 787807502.0252 - val_loss: 707567680.0000\n",
      "Epoch 481/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774843840.000 - 0s 53us/step - loss: 787806547.5063 - val_loss: 707566720.0000\n",
      "Epoch 482/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778237120.000 - 0s 55us/step - loss: 787805616.8463 - val_loss: 707565760.0000\n",
      "Epoch 483/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 764037632.000 - 0s 53us/step - loss: 787804686.8312 - val_loss: 707564800.0000\n",
      "Epoch 484/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785499136.000 - 0s 50us/step - loss: 787803757.1385 - val_loss: 707563904.0000\n",
      "Epoch 485/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779254528.000 - 0s 55us/step - loss: 787802808.9068 - val_loss: 707562944.0000\n",
      "Epoch 486/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 810882112.000 - 0s 53us/step - loss: 787801871.3149 - val_loss: 707561920.0000\n",
      "Epoch 487/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795503360.000 - 0s 58us/step - loss: 787800920.1814 - val_loss: 707561088.0000\n",
      "Epoch 488/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799081536.000 - 0s 53us/step - loss: 787800040.1411 - val_loss: 707560192.0000\n",
      "Epoch 489/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 822268096.000 - 0s 58us/step - loss: 787799100.1310 - val_loss: 707559168.0000\n",
      "Epoch 490/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782281216.000 - 0s 50us/step - loss: 787798175.2746 - val_loss: 707558208.0000\n",
      "Epoch 491/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 751563392.000 - 0s 55us/step - loss: 787797228.6549 - val_loss: 707557312.0000\n",
      "Epoch 492/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780393472.000 - 0s 53us/step - loss: 787796281.0680 - val_loss: 707556288.0000\n",
      "Epoch 493/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 771341376.000 - 0s 55us/step - loss: 787795344.7657 - val_loss: 707555392.0000\n",
      "Epoch 494/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 831388032.000 - 0s 53us/step - loss: 787794446.8312 - val_loss: 707554432.0000\n",
      "Epoch 495/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 760949248.000 - 0s 55us/step - loss: 787793478.4484 - val_loss: 707553536.0000\n",
      "Epoch 496/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 800290304.000 - 0s 55us/step - loss: 787792521.6725 - val_loss: 707552512.0000\n",
      "Epoch 497/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 749335296.000 - 0s 53us/step - loss: 787791626.4786 - val_loss: 707551680.0000\n",
      "Epoch 498/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774724544.000 - 0s 53us/step - loss: 787790670.5088 - val_loss: 707550784.0000\n",
      "Epoch 499/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773192960.000 - 0s 53us/step - loss: 787789772.5743 - val_loss: 707549760.0000\n",
      "Epoch 500/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 815845312.000 - 0s 50us/step - loss: 787788835.6272 - val_loss: 707548800.0000\n",
      "Epoch 501/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762406528.000 - 0s 55us/step - loss: 787787869.3401 - val_loss: 707547840.0000\n",
      "Epoch 502/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781357120.000 - 0s 50us/step - loss: 787786931.9093 - val_loss: 707546880.0000\n",
      "Epoch 503/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801564224.000 - 0s 55us/step - loss: 787786002.2166 - val_loss: 707545920.0000\n",
      "Epoch 504/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786473088.000 - 0s 55us/step - loss: 787785098.4786 - val_loss: 707545024.0000\n",
      "Epoch 505/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780522752.000 - 0s 53us/step - loss: 787784160.7254 - val_loss: 707544064.0000\n",
      "Epoch 506/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779562624.000 - 0s 53us/step - loss: 787783182.5088 - val_loss: 707543104.0000\n",
      "Epoch 507/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781691136.000 - 0s 50us/step - loss: 787782256.2015 - val_loss: 707542208.0000\n",
      "Epoch 508/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791311360.000 - 0s 58us/step - loss: 787781358.5894 - val_loss: 707541248.0000\n",
      "Epoch 509/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799300736.000 - 0s 53us/step - loss: 787780403.2645 - val_loss: 707540224.0000\n",
      "Epoch 510/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 816500288.000 - 0s 58us/step - loss: 787779434.8816 - val_loss: 707539392.0000\n",
      "Epoch 511/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 820051072.000 - 0s 53us/step - loss: 787778482.2972 - val_loss: 707538368.0000\n",
      "Epoch 512/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769578624.000 - 0s 53us/step - loss: 787777554.2166 - val_loss: 707537408.0000\n",
      "Epoch 513/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776847360.000 - 0s 53us/step - loss: 787776632.4232 - val_loss: 707536448.0000\n",
      "Epoch 514/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801393024.000 - 0s 53us/step - loss: 787775701.1184 - val_loss: 707535616.0000\n",
      "Epoch 515/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785321088.000 - 0s 53us/step - loss: 787774801.4106 - val_loss: 707534656.0000\n",
      "Epoch 516/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 723130816.000 - 0s 53us/step - loss: 787773887.1940 - val_loss: 707533760.0000\n",
      "Epoch 517/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756230400.000 - 0s 53us/step - loss: 787772936.3829 - val_loss: 707532800.0000\n",
      "Epoch 518/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793953600.000 - 0s 55us/step - loss: 787772011.8489 - val_loss: 707531904.0000\n",
      "Epoch 519/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806578176.000 - 0s 58us/step - loss: 787771142.1259 - val_loss: 707530880.0000\n",
      "Epoch 520/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 737885568.000 - 0s 55us/step - loss: 787770203.8892 - val_loss: 707529984.0000\n",
      "Epoch 521/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806239168.000 - 0s 58us/step - loss: 787769291.7683 - val_loss: 707529088.0000\n",
      "Epoch 522/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792058240.000 - 0s 55us/step - loss: 787768372.2317 - val_loss: 707528128.0000\n",
      "Epoch 523/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786764160.000 - 0s 55us/step - loss: 787767466.3980 - val_loss: 707527232.0000\n",
      "Epoch 524/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781131072.000 - 0s 53us/step - loss: 787766527.8388 - val_loss: 707526272.0000\n",
      "Epoch 525/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793130560.000 - 0s 53us/step - loss: 787765606.8514 - val_loss: 707525376.0000\n",
      "Epoch 526/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784939584.000 - 0s 55us/step - loss: 787764681.5113 - val_loss: 707524352.0000\n",
      "Epoch 527/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798455488.000 - 0s 53us/step - loss: 787763716.6751 - val_loss: 707523456.0000\n",
      "Epoch 528/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 833559296.000 - 0s 53us/step - loss: 787762827.4458 - val_loss: 707522560.0000\n",
      "Epoch 529/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779972736.000 - 0s 58us/step - loss: 787761910.9723 - val_loss: 707521600.0000\n",
      "Epoch 530/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 836810432.000 - 0s 53us/step - loss: 787760924.8564 - val_loss: 707520576.0000\n",
      "Epoch 531/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799516544.000 - 0s 53us/step - loss: 787760009.6725 - val_loss: 707519680.0000\n",
      "Epoch 532/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780166464.000 - 0s 55us/step - loss: 787759118.6700 - val_loss: 707518784.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790320896.000 - 0s 50us/step - loss: 787758127.3955 - val_loss: 707517888.0000\n",
      "Epoch 534/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806123264.000 - 0s 50us/step - loss: 787757202.8615 - val_loss: 707516928.0000\n",
      "Epoch 535/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781677952.000 - 0s 58us/step - loss: 787756265.7531 - val_loss: 707516032.0000\n",
      "Epoch 536/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 766890752.000 - 0s 50us/step - loss: 787755404.5743 - val_loss: 707515136.0000\n",
      "Epoch 537/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763536384.000 - 0s 58us/step - loss: 787754425.0680 - val_loss: 707514176.0000\n",
      "Epoch 538/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785237056.000 - 0s 50us/step - loss: 787753492.1511 - val_loss: 707513152.0000\n",
      "Epoch 539/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777308416.000 - 0s 50us/step - loss: 787752567.4559 - val_loss: 707512256.0000\n",
      "Epoch 540/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 747614976.000 - 0s 53us/step - loss: 787751638.4081 - val_loss: 707511296.0000\n",
      "Epoch 541/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781041152.000 - 0s 53us/step - loss: 787750712.4232 - val_loss: 707510336.0000\n",
      "Epoch 542/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756447744.000 - 0s 55us/step - loss: 787749760.9673 - val_loss: 707509312.0000\n",
      "Epoch 543/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780054656.000 - 0s 50us/step - loss: 787748839.0126 - val_loss: 707508480.0000\n",
      "Epoch 544/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 824480704.000 - 0s 48us/step - loss: 787747899.4861 - val_loss: 707507456.0000\n",
      "Epoch 545/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777608768.000 - 0s 55us/step - loss: 787746969.9547 - val_loss: 707506496.0000\n",
      "Epoch 546/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 841598400.000 - 0s 53us/step - loss: 787746018.4987 - val_loss: 707505600.0000\n",
      "Epoch 547/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806438528.000 - 0s 55us/step - loss: 787745092.0302 - val_loss: 707504640.0000\n",
      "Epoch 548/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 815728256.000 - 0s 53us/step - loss: 787744180.5542 - val_loss: 707503680.0000\n",
      "Epoch 549/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792027904.000 - 0s 53us/step - loss: 787743236.6751 - val_loss: 707502720.0000\n",
      "Epoch 550/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 764311488.000 - 0s 53us/step - loss: 787742318.5894 - val_loss: 707501888.0000\n",
      "Epoch 551/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797348416.000 - 0s 50us/step - loss: 787741406.4685 - val_loss: 707500992.0000\n",
      "Epoch 552/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 859787264.000 - 0s 58us/step - loss: 787740465.0076 - val_loss: 707499968.0000\n",
      "Epoch 553/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796903744.000 - 0s 50us/step - loss: 787739517.2594 - val_loss: 707499008.0000\n",
      "Epoch 554/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769449600.000 - 0s 55us/step - loss: 787738588.6952 - val_loss: 707498112.0000\n",
      "Epoch 555/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799029952.000 - 0s 53us/step - loss: 787737669.4811 - val_loss: 707497216.0000\n",
      "Epoch 556/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772235968.000 - 0s 50us/step - loss: 787736755.9093 - val_loss: 707496256.0000\n",
      "Epoch 557/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794666880.000 - 0s 55us/step - loss: 787735833.9547 - val_loss: 707495232.0000\n",
      "Epoch 558/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 764172224.000 - 0s 50us/step - loss: 787734910.5491 - val_loss: 707494336.0000\n",
      "Epoch 559/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785228672.000 - 0s 50us/step - loss: 787733945.0680 - val_loss: 707493440.0000\n",
      "Epoch 560/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781879232.000 - 0s 53us/step - loss: 787733041.6524 - val_loss: 707492480.0000\n",
      "Epoch 561/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770459264.000 - 0s 53us/step - loss: 787732134.2065 - val_loss: 707491584.0000\n",
      "Epoch 562/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 815843968.000 - 0s 55us/step - loss: 787731211.7683 - val_loss: 707490624.0000\n",
      "Epoch 563/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786488064.000 - 0s 50us/step - loss: 787730225.4912 - val_loss: 707489664.0000\n",
      "Epoch 564/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793960064.000 - 0s 53us/step - loss: 787729309.1788 - val_loss: 707488704.0000\n",
      "Epoch 565/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 837988736.000 - 0s 55us/step - loss: 787728420.4332 - val_loss: 707487808.0000\n",
      "Epoch 566/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814504832.000 - 0s 45us/step - loss: 787727495.8992 - val_loss: 707486912.0000\n",
      "Epoch 567/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805073216.000 - 0s 53us/step - loss: 787726563.3048 - val_loss: 707485952.0000\n",
      "Epoch 568/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 766498944.000 - 0s 50us/step - loss: 787725610.2368 - val_loss: 707484928.0000\n",
      "Epoch 569/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 728538176.000 - 0s 58us/step - loss: 787724664.2620 - val_loss: 707484096.0000\n",
      "Epoch 570/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 823472832.000 - 0s 55us/step - loss: 787723759.0730 - val_loss: 707483136.0000\n",
      "Epoch 571/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797938944.000 - 0s 55us/step - loss: 787722830.3476 - val_loss: 707482176.0000\n",
      "Epoch 572/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797374720.000 - 0s 55us/step - loss: 787721888.2418 - val_loss: 707481216.0000\n",
      "Epoch 573/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798603008.000 - 0s 58us/step - loss: 787720950.1662 - val_loss: 707480320.0000\n",
      "Epoch 574/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 824058624.000 - 0s 53us/step - loss: 787720027.2443 - val_loss: 707479360.0000\n",
      "Epoch 575/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811178368.000 - 0s 55us/step - loss: 787719093.0378 - val_loss: 707478464.0000\n",
      "Epoch 576/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780104512.000 - 0s 55us/step - loss: 787718156.8967 - val_loss: 707477440.0000\n",
      "Epoch 577/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772326400.000 - 0s 50us/step - loss: 787717171.1839 - val_loss: 707476544.0000\n",
      "Epoch 578/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798800832.000 - 0s 53us/step - loss: 787716305.8942 - val_loss: 707475648.0000\n",
      "Epoch 579/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 727556928.000 - 0s 55us/step - loss: 787715376.5239 - val_loss: 707474688.0000\n",
      "Epoch 580/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781245440.000 - 0s 55us/step - loss: 787714496.0000 - val_loss: 707473792.0000\n",
      "Epoch 581/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794581376.000 - 0s 55us/step - loss: 787713551.9597 - val_loss: 707472768.0000\n",
      "Epoch 582/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785710336.000 - 0s 55us/step - loss: 787712594.0554 - val_loss: 707471808.0000\n",
      "Epoch 583/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 744111296.000 - 0s 55us/step - loss: 787711696.4433 - val_loss: 707470912.0000\n",
      "Epoch 584/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774044544.000 - 0s 58us/step - loss: 787710727.7380 - val_loss: 707470016.0000\n",
      "Epoch 585/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 749613440.000 - 0s 55us/step - loss: 787709778.8615 - val_loss: 707469056.0000\n",
      "Epoch 586/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - ETA: 0s - loss: 807505408.000 - 0s 53us/step - loss: 787708854.8111 - val_loss: 707468160.0000\n",
      "Epoch 587/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 819662464.000 - 0s 55us/step - loss: 787707944.7859 - val_loss: 707467200.0000\n",
      "Epoch 588/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781637248.000 - 0s 50us/step - loss: 787706992.8463 - val_loss: 707466240.0000\n",
      "Epoch 589/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793779840.000 - 0s 53us/step - loss: 787706114.5793 - val_loss: 707465280.0000\n",
      "Epoch 590/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774158336.000 - 0s 53us/step - loss: 787705162.4786 - val_loss: 707464384.0000\n",
      "Epoch 591/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 771185216.000 - 0s 58us/step - loss: 787704215.6977 - val_loss: 707463424.0000\n",
      "Epoch 592/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 833264320.000 - 0s 55us/step - loss: 787703301.8035 - val_loss: 707462464.0000\n",
      "Epoch 593/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769680768.000 - 0s 50us/step - loss: 787702353.7330 - val_loss: 707461568.0000\n",
      "Epoch 594/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780448576.000 - 0s 53us/step - loss: 787701420.0101 - val_loss: 707460544.0000\n",
      "Epoch 595/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762353920.000 - 0s 53us/step - loss: 787700490.3174 - val_loss: 707459648.0000\n",
      "Epoch 596/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770492928.000 - 0s 55us/step - loss: 787699543.3753 - val_loss: 707458688.0000\n",
      "Epoch 597/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794339584.000 - 0s 53us/step - loss: 787698669.4610 - val_loss: 707457728.0000\n",
      "Epoch 598/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787859904.000 - 0s 55us/step - loss: 787697695.5970 - val_loss: 707456832.0000\n",
      "Epoch 599/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807369856.000 - 0s 53us/step - loss: 787696753.6524 - val_loss: 707455872.0000\n",
      "Epoch 600/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 745587456.000 - 0s 53us/step - loss: 787695789.2997 - val_loss: 707454912.0000\n",
      "Epoch 601/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797232768.000 - 0s 55us/step - loss: 787694917.8035 - val_loss: 707453952.0000\n",
      "Epoch 602/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787747136.000 - 0s 53us/step - loss: 787693974.8917 - val_loss: 707453056.0000\n",
      "Epoch 603/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801003328.000 - 0s 58us/step - loss: 787693075.3451 - val_loss: 707452160.0000\n",
      "Epoch 604/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 766009344.000 - 0s 53us/step - loss: 787692176.9270 - val_loss: 707451264.0000\n",
      "Epoch 605/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782250560.000 - 0s 50us/step - loss: 787691219.1839 - val_loss: 707450368.0000\n",
      "Epoch 606/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787599872.000 - 0s 55us/step - loss: 787690333.9849 - val_loss: 707449408.0000\n",
      "Epoch 607/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 759781248.000 - 0s 50us/step - loss: 787689430.2469 - val_loss: 707448384.0000\n",
      "Epoch 608/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791032064.000 - 0s 55us/step - loss: 787688533.7632 - val_loss: 707447552.0000\n",
      "Epoch 609/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782416576.000 - 0s 55us/step - loss: 787687562.9622 - val_loss: 707446592.0000\n",
      "Epoch 610/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 836153216.000 - 0s 55us/step - loss: 787686608.4433 - val_loss: 707445632.0000\n",
      "Epoch 611/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 826222208.000 - 0s 53us/step - loss: 787685670.8514 - val_loss: 707444672.0000\n",
      "Epoch 612/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773509440.000 - 0s 55us/step - loss: 787684763.8892 - val_loss: 707443712.0000\n",
      "Epoch 613/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 789061248.000 - 0s 55us/step - loss: 787683772.2922 - val_loss: 707442816.0000\n",
      "Epoch 614/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801122752.000 - 0s 58us/step - loss: 787682877.5819 - val_loss: 707441856.0000\n",
      "Epoch 615/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783402624.000 - 0s 55us/step - loss: 787681966.5894 - val_loss: 707440896.0000\n",
      "Epoch 616/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762469184.000 - 0s 53us/step - loss: 787681013.8438 - val_loss: 707440000.0000\n",
      "Epoch 617/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782816064.000 - 0s 53us/step - loss: 787680109.7834 - val_loss: 707439040.0000\n",
      "Epoch 618/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 775112128.000 - 0s 53us/step - loss: 787679194.9219 - val_loss: 707438144.0000\n",
      "Epoch 619/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776098688.000 - 0s 53us/step - loss: 787678254.1058 - val_loss: 707437184.0000\n",
      "Epoch 620/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 789014336.000 - 0s 55us/step - loss: 787677367.2947 - val_loss: 707436288.0000\n",
      "Epoch 621/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 837439232.000 - 0s 53us/step - loss: 787676384.0806 - val_loss: 707435328.0000\n",
      "Epoch 622/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769942784.000 - 0s 55us/step - loss: 787675492.1108 - val_loss: 707434432.0000\n",
      "Epoch 623/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807724608.000 - 0s 53us/step - loss: 787674570.7204 - val_loss: 707433472.0000\n",
      "Epoch 624/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 808663040.000 - 0s 53us/step - loss: 787673657.5516 - val_loss: 707432512.0000\n",
      "Epoch 625/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776213760.000 - 0s 53us/step - loss: 787672697.7128 - val_loss: 707431616.0000\n",
      "Epoch 626/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805100672.000 - 0s 58us/step - loss: 787671823.9597 - val_loss: 707430656.0000\n",
      "Epoch 627/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783221120.000 - 0s 55us/step - loss: 787670864.6045 - val_loss: 707429696.0000\n",
      "Epoch 628/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796688256.000 - 0s 55us/step - loss: 787669930.3980 - val_loss: 707428800.0000\n",
      "Epoch 629/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 761518016.000 - 0s 53us/step - loss: 787669033.1083 - val_loss: 707427840.0000\n",
      "Epoch 630/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 775344768.000 - 0s 53us/step - loss: 787668120.3426 - val_loss: 707426944.0000\n",
      "Epoch 631/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774690048.000 - 0s 55us/step - loss: 787667183.8791 - val_loss: 707426048.0000\n",
      "Epoch 632/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 740086912.000 - 0s 53us/step - loss: 787666239.8388 - val_loss: 707425088.0000\n",
      "Epoch 633/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 775595904.000 - 0s 53us/step - loss: 787665315.6272 - val_loss: 707424064.0000\n",
      "Epoch 634/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762552064.000 - 0s 50us/step - loss: 787664391.2544 - val_loss: 707423168.0000\n",
      "Epoch 635/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785381248.000 - 0s 50us/step - loss: 787663457.2091 - val_loss: 707422272.0000\n",
      "Epoch 636/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786925824.000 - 0s 55us/step - loss: 787662498.0957 - val_loss: 707421312.0000\n",
      "Epoch 637/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780178176.000 - 0s 55us/step - loss: 787661598.9521 - val_loss: 707420416.0000\n",
      "Epoch 638/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 766886912.000 - 0s 55us/step - loss: 787660655.5567 - val_loss: 707419392.0000\n",
      "Epoch 639/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809296448.000 - 0s 48us/step - loss: 787659718.9320 - val_loss: 707418496.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 640/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773820480.000 - 0s 50us/step - loss: 787658824.8665 - val_loss: 707417536.0000\n",
      "Epoch 641/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 800278656.000 - 0s 53us/step - loss: 787657931.2846 - val_loss: 707416640.0000\n",
      "Epoch 642/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 828593280.000 - 0s 50us/step - loss: 787656948.7154 - val_loss: 707415680.0000\n",
      "Epoch 643/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 818935040.000 - 0s 58us/step - loss: 787656007.7380 - val_loss: 707414720.0000\n",
      "Epoch 644/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774018624.000 - 0s 53us/step - loss: 787655096.1008 - val_loss: 707413760.0000\n",
      "Epoch 645/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795838016.000 - 0s 53us/step - loss: 787654157.3804 - val_loss: 707412928.0000\n",
      "Epoch 646/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 834678464.000 - 0s 53us/step - loss: 787653220.9169 - val_loss: 707411904.0000\n",
      "Epoch 647/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801253824.000 - 0s 50us/step - loss: 787652268.0101 - val_loss: 707410944.0000\n",
      "Epoch 648/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778256896.000 - 0s 55us/step - loss: 787651344.9270 - val_loss: 707409984.0000\n",
      "Epoch 649/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807969856.000 - 0s 53us/step - loss: 787650430.2267 - val_loss: 707409088.0000\n",
      "Epoch 650/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 815001920.000 - 0s 53us/step - loss: 787649486.6700 - val_loss: 707408128.0000\n",
      "Epoch 651/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 765644928.000 - 0s 58us/step - loss: 787648544.7254 - val_loss: 707407168.0000\n",
      "Epoch 652/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806032704.000 - 0s 50us/step - loss: 787647625.1889 - val_loss: 707406208.0000\n",
      "Epoch 653/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 738881152.000 - 0s 68us/step - loss: 787646695.9798 - val_loss: 707405376.0000\n",
      "Epoch 654/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 803590144.000 - 0s 58us/step - loss: 787645789.1788 - val_loss: 707404352.0000\n",
      "Epoch 655/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805700992.000 - 0s 50us/step - loss: 787644839.1738 - val_loss: 707403456.0000\n",
      "Epoch 656/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779688064.000 - 0s 50us/step - loss: 787643917.3804 - val_loss: 707402496.0000\n",
      "Epoch 657/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796629888.000 - 0s 55us/step - loss: 787642966.7305 - val_loss: 707401600.0000\n",
      "Epoch 658/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791665088.000 - 0s 50us/step - loss: 787642040.9068 - val_loss: 707400640.0000\n",
      "Epoch 659/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 816177280.000 - 0s 58us/step - loss: 787641101.3804 - val_loss: 707399616.0000\n",
      "Epoch 660/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797492160.000 - 0s 53us/step - loss: 787640140.2519 - val_loss: 707398720.0000\n",
      "Epoch 661/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786601984.000 - 0s 55us/step - loss: 787639233.4509 - val_loss: 707397824.0000\n",
      "Epoch 662/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781030400.000 - 0s 53us/step - loss: 787638293.4408 - val_loss: 707396864.0000\n",
      "Epoch 663/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786260608.000 - 0s 55us/step - loss: 787637397.2796 - val_loss: 707395840.0000\n",
      "Epoch 664/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 738284800.000 - 0s 53us/step - loss: 787636443.4055 - val_loss: 707395008.0000\n",
      "Epoch 665/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790502528.000 - 0s 53us/step - loss: 787635529.5113 - val_loss: 707394048.0000\n",
      "Epoch 666/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 757112320.000 - 0s 55us/step - loss: 787634583.6977 - val_loss: 707393088.0000\n",
      "Epoch 667/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 775973312.000 - 0s 53us/step - loss: 787633615.3149 - val_loss: 707392128.0000\n",
      "Epoch 668/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 828464192.000 - 0s 53us/step - loss: 787632698.5189 - val_loss: 707391232.0000\n",
      "Epoch 669/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782738944.000 - 0s 50us/step - loss: 787631792.2015 - val_loss: 707390208.0000\n",
      "Epoch 670/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767878272.000 - 0s 50us/step - loss: 787630785.7733 - val_loss: 707389248.0000\n",
      "Epoch 671/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777349248.000 - 0s 55us/step - loss: 787629821.0982 - val_loss: 707388352.0000\n",
      "Epoch 672/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792573952.000 - 0s 53us/step - loss: 787628901.7229 - val_loss: 707387392.0000\n",
      "Epoch 673/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 812115328.000 - 0s 60us/step - loss: 787627969.4509 - val_loss: 707386432.0000\n",
      "Epoch 674/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773346624.000 - 0s 55us/step - loss: 787627041.5315 - val_loss: 707385472.0000\n",
      "Epoch 675/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787172352.000 - 0s 53us/step - loss: 787626139.2443 - val_loss: 707384576.0000\n",
      "Epoch 676/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 746524352.000 - 0s 55us/step - loss: 787625161.5113 - val_loss: 707383680.0000\n",
      "Epoch 677/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792292992.000 - 0s 60us/step - loss: 787624225.6927 - val_loss: 707382720.0000\n",
      "Epoch 678/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 850697600.000 - 0s 53us/step - loss: 787623322.9219 - val_loss: 707381696.0000\n",
      "Epoch 679/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768302720.000 - 0s 55us/step - loss: 787622331.3249 - val_loss: 707380800.0000\n",
      "Epoch 680/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 842136960.000 - 0s 55us/step - loss: 787621444.0302 - val_loss: 707379904.0000\n",
      "Epoch 681/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799438080.000 - 0s 55us/step - loss: 787620527.8791 - val_loss: 707378880.0000\n",
      "Epoch 682/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773335680.000 - 0s 55us/step - loss: 787619602.5390 - val_loss: 707377984.0000\n",
      "Epoch 683/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 835982848.000 - 0s 55us/step - loss: 787618657.6927 - val_loss: 707377088.0000\n",
      "Epoch 684/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794750592.000 - 0s 55us/step - loss: 787617760.7254 - val_loss: 707376128.0000\n",
      "Epoch 685/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784382720.000 - 0s 55us/step - loss: 787616824.5844 - val_loss: 707375168.0000\n",
      "Epoch 686/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805976064.000 - 0s 55us/step - loss: 787615856.5239 - val_loss: 707374144.0000\n",
      "Epoch 687/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781604352.000 - 0s 55us/step - loss: 787614904.9068 - val_loss: 707373312.0000\n",
      "Epoch 688/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 837504768.000 - 0s 55us/step - loss: 787614011.0025 - val_loss: 707372288.0000\n",
      "Epoch 689/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 803036096.000 - 0s 55us/step - loss: 787613093.2393 - val_loss: 707371392.0000\n",
      "Epoch 690/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 804066688.000 - 0s 55us/step - loss: 787612120.3426 - val_loss: 707370432.0000\n",
      "Epoch 691/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783934080.000 - 0s 55us/step - loss: 787611195.0025 - val_loss: 707369536.0000\n",
      "Epoch 692/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793086592.000 - 0s 55us/step - loss: 787610246.4484 - val_loss: 707368512.0000\n",
      "Epoch 693/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - ETA: 0s - loss: 808368384.000 - 0s 58us/step - loss: 787609280.4836 - val_loss: 707367552.0000\n",
      "Epoch 694/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 775552448.000 - 0s 48us/step - loss: 787608361.4307 - val_loss: 707366656.0000\n",
      "Epoch 695/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806311232.000 - 0s 53us/step - loss: 787607433.6725 - val_loss: 707365696.0000\n",
      "Epoch 696/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 834968896.000 - 0s 58us/step - loss: 787606505.7531 - val_loss: 707364736.0000\n",
      "Epoch 697/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756813184.000 - 0s 55us/step - loss: 787605530.1159 - val_loss: 707363776.0000\n",
      "Epoch 698/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 764859200.000 - 0s 65us/step - loss: 787604642.9824 - val_loss: 707362816.0000\n",
      "Epoch 699/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 752272704.000 - 0s 65us/step - loss: 787603698.1360 - val_loss: 707361856.0000\n",
      "Epoch 700/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805253376.000 - 0s 55us/step - loss: 787602774.0856 - val_loss: 707360960.0000\n",
      "Epoch 701/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 810259392.000 - 0s 60us/step - loss: 787601846.0050 - val_loss: 707360000.0000\n",
      "Epoch 702/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770638976.000 - 0s 58us/step - loss: 787600876.8161 - val_loss: 707359168.0000\n",
      "Epoch 703/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799252992.000 - 0s 53us/step - loss: 787599948.2519 - val_loss: 707358144.0000\n",
      "Epoch 704/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 752556352.000 - 0s 50us/step - loss: 787599000.8262 - val_loss: 707357184.0000\n",
      "Epoch 705/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755020800.000 - 0s 50us/step - loss: 787598101.1184 - val_loss: 707356288.0000\n",
      "Epoch 706/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 751270144.000 - 0s 53us/step - loss: 787597203.6675 - val_loss: 707355392.0000\n",
      "Epoch 707/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 823995712.000 - 0s 50us/step - loss: 787596236.7355 - val_loss: 707354368.0000\n",
      "Epoch 708/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783408384.000 - 0s 55us/step - loss: 787595271.8992 - val_loss: 707353408.0000\n",
      "Epoch 709/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 813889408.000 - 0s 53us/step - loss: 787594363.3249 - val_loss: 707352512.0000\n",
      "Epoch 710/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806327232.000 - 0s 50us/step - loss: 787593451.6877 - val_loss: 707351552.0000\n",
      "Epoch 711/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773983360.000 - 0s 53us/step - loss: 787592493.9446 - val_loss: 707350592.0000\n",
      "Epoch 712/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798335680.000 - 0s 50us/step - loss: 787591539.7481 - val_loss: 707349632.0000\n",
      "Epoch 713/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 810681792.000 - 0s 58us/step - loss: 787590610.5390 - val_loss: 707348672.0000\n",
      "Epoch 714/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 750796288.000 - 0s 53us/step - loss: 787589681.9748 - val_loss: 707347712.0000\n",
      "Epoch 715/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 764760128.000 - 0s 58us/step - loss: 787588771.6272 - val_loss: 707346816.0000\n",
      "Epoch 716/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 788975168.000 - 0s 50us/step - loss: 787587804.3728 - val_loss: 707345856.0000\n",
      "Epoch 717/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 817557504.000 - 0s 53us/step - loss: 787586834.5390 - val_loss: 707344960.0000\n",
      "Epoch 718/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 751338624.000 - 0s 55us/step - loss: 787585954.8212 - val_loss: 707343936.0000\n",
      "Epoch 719/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798724608.000 - 0s 53us/step - loss: 787584997.4005 - val_loss: 707343040.0000\n",
      "Epoch 720/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781892480.000 - 0s 58us/step - loss: 787584101.4005 - val_loss: 707342080.0000\n",
      "Epoch 721/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 766358592.000 - 0s 58us/step - loss: 787583095.4559 - val_loss: 707341120.0000\n",
      "Epoch 722/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 771822720.000 - 0s 50us/step - loss: 787582177.0479 - val_loss: 707340224.0000\n",
      "Epoch 723/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792560064.000 - 0s 53us/step - loss: 787581225.2695 - val_loss: 707339200.0000\n",
      "Epoch 724/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782835136.000 - 0s 53us/step - loss: 787580296.8665 - val_loss: 707338240.0000\n",
      "Epoch 725/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797115136.000 - 0s 63us/step - loss: 787579345.0882 - val_loss: 707337344.0000\n",
      "Epoch 726/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772404480.000 - 0s 63us/step - loss: 787578411.5264 - val_loss: 707336384.0000\n",
      "Epoch 727/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 764610816.000 - 0s 60us/step - loss: 787577482.8010 - val_loss: 707335424.0000\n",
      "Epoch 728/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 819920128.000 - 0s 63us/step - loss: 787576573.4207 - val_loss: 707334528.0000\n",
      "Epoch 729/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805278720.000 - 0s 58us/step - loss: 787575621.6423 - val_loss: 707333632.0000\n",
      "Epoch 730/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791168512.000 - 0s 58us/step - loss: 787574715.9698 - val_loss: 707332672.0000\n",
      "Epoch 731/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 749372096.000 - 0s 60us/step - loss: 787573737.1083 - val_loss: 707331712.0000\n",
      "Epoch 732/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805794176.000 - 0s 63us/step - loss: 787572881.4106 - val_loss: 707330816.0000\n",
      "Epoch 733/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777373056.000 - 0s 60us/step - loss: 787571910.9320 - val_loss: 707329792.0000\n",
      "Epoch 734/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 764567232.000 - 0s 53us/step - loss: 787571005.0982 - val_loss: 707328896.0000\n",
      "Epoch 735/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814332736.000 - 0s 53us/step - loss: 787570058.3174 - val_loss: 707327936.0000\n",
      "Epoch 736/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 805575040.000 - 0s 53us/step - loss: 787569150.5491 - val_loss: 707327040.0000\n",
      "Epoch 737/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807019008.000 - 0s 58us/step - loss: 787568236.0101 - val_loss: 707326144.0000\n",
      "Epoch 738/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 812617728.000 - 0s 55us/step - loss: 787567301.9647 - val_loss: 707325184.0000\n",
      "Epoch 739/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 748463488.000 - 0s 58us/step - loss: 787566349.8640 - val_loss: 707324160.0000\n",
      "Epoch 740/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767011840.000 - 0s 53us/step - loss: 787565381.4811 - val_loss: 707323328.0000\n",
      "Epoch 741/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768897664.000 - 0s 53us/step - loss: 787564435.8287 - val_loss: 707322304.0000\n",
      "Epoch 742/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806489984.000 - 0s 50us/step - loss: 787563588.9975 - val_loss: 707321408.0000\n",
      "Epoch 743/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 800703616.000 - 0s 53us/step - loss: 787562580.9572 - val_loss: 707320512.0000\n",
      "Epoch 744/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797865088.000 - 0s 58us/step - loss: 787561695.5970 - val_loss: 707319552.0000\n",
      "Epoch 745/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 806808832.000 - 0s 55us/step - loss: 787560783.9597 - val_loss: 707318592.0000\n",
      "Epoch 746/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781932224.000 - 0s 58us/step - loss: 787559824.7657 - val_loss: 707317632.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 747/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785303296.000 - 0s 58us/step - loss: 787558935.5365 - val_loss: 707316736.0000\n",
      "Epoch 748/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 757610304.000 - 0s 53us/step - loss: 787557999.2343 - val_loss: 707315776.0000\n",
      "Epoch 749/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 726400448.000 - 0s 53us/step - loss: 787557081.7935 - val_loss: 707314816.0000\n",
      "Epoch 750/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 725124992.000 - 0s 53us/step - loss: 787556110.5088 - val_loss: 707313856.0000\n",
      "Epoch 751/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 818105600.000 - 0s 63us/step - loss: 787555163.7280 - val_loss: 707312896.0000\n",
      "Epoch 752/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814310208.000 - 0s 60us/step - loss: 787554213.7229 - val_loss: 707312000.0000\n",
      "Epoch 753/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 760525696.000 - 0s 58us/step - loss: 787553288.5441 - val_loss: 707311040.0000\n",
      "Epoch 754/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 753286592.000 - 0s 58us/step - loss: 787552346.7607 - val_loss: 707310016.0000\n",
      "Epoch 755/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 746307328.000 - 0s 58us/step - loss: 787551431.0932 - val_loss: 707309120.0000\n",
      "Epoch 756/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797228928.000 - 0s 58us/step - loss: 787550490.7607 - val_loss: 707308224.0000\n",
      "Epoch 757/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 804304768.000 - 0s 58us/step - loss: 787549531.8892 - val_loss: 707307264.0000\n",
      "Epoch 758/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769005504.000 - 0s 58us/step - loss: 787548613.1587 - val_loss: 707306240.0000\n",
      "Epoch 759/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811507968.000 - 0s 60us/step - loss: 787547696.2015 - val_loss: 707305408.0000\n",
      "Epoch 760/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796389248.000 - 0s 58us/step - loss: 787546740.8766 - val_loss: 707304448.0000\n",
      "Epoch 761/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793262976.000 - 0s 60us/step - loss: 787545811.9899 - val_loss: 707303488.0000\n",
      "Epoch 762/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763343104.000 - 0s 55us/step - loss: 787544931.1436 - val_loss: 707302592.0000\n",
      "Epoch 763/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 764123072.000 - 0s 63us/step - loss: 787544017.4106 - val_loss: 707301632.0000\n",
      "Epoch 764/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802137728.000 - 0s 58us/step - loss: 787543063.8589 - val_loss: 707300672.0000\n",
      "Epoch 765/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 822782848.000 - 0s 58us/step - loss: 787542150.4484 - val_loss: 707299776.0000\n",
      "Epoch 766/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785543296.000 - 0s 58us/step - loss: 787541213.8237 - val_loss: 707298880.0000\n",
      "Epoch 767/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783750656.000 - 0s 55us/step - loss: 787540262.5290 - val_loss: 707297920.0000\n",
      "Epoch 768/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784326592.000 - 0s 65us/step - loss: 787539390.3879 - val_loss: 707297024.0000\n",
      "Epoch 769/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792615872.000 - 0s 50us/step - loss: 787538429.7431 - val_loss: 707296064.0000\n",
      "Epoch 770/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768552256.000 - 0s 50us/step - loss: 787537526.3275 - val_loss: 707295168.0000\n",
      "Epoch 771/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 835481728.000 - 0s 53us/step - loss: 787536606.7909 - val_loss: 707294144.0000\n",
      "Epoch 772/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 804306688.000 - 0s 48us/step - loss: 787535692.4131 - val_loss: 707293248.0000\n",
      "Epoch 773/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814545088.000 - 0s 53us/step - loss: 787534751.5970 - val_loss: 707292352.0000\n",
      "Epoch 774/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 760542208.000 - 0s 50us/step - loss: 787533842.3778 - val_loss: 707291392.0000\n",
      "Epoch 775/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809128832.000 - 0s 48us/step - loss: 787532910.2670 - val_loss: 707290432.0000\n",
      "Epoch 776/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767283648.000 - 0s 53us/step - loss: 787531974.1259 - val_loss: 707289472.0000\n",
      "Epoch 777/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780766272.000 - 0s 53us/step - loss: 787531016.0605 - val_loss: 707288576.0000\n",
      "Epoch 778/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 804630144.000 - 0s 48us/step - loss: 787530141.3401 - val_loss: 707287616.0000\n",
      "Epoch 779/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 849922816.000 - 0s 53us/step - loss: 787529175.5365 - val_loss: 707286656.0000\n",
      "Epoch 780/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 735416320.000 - 0s 50us/step - loss: 787528209.5718 - val_loss: 707285760.0000\n",
      "Epoch 781/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 826616448.000 - 0s 50us/step - loss: 787527280.5239 - val_loss: 707284800.0000\n",
      "Epoch 782/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781051712.000 - 0s 55us/step - loss: 787526334.2267 - val_loss: 707283904.0000\n",
      "Epoch 783/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 761254656.000 - 0s 55us/step - loss: 787525484.8161 - val_loss: 707282944.0000\n",
      "Epoch 784/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781305984.000 - 0s 58us/step - loss: 787524479.8388 - val_loss: 707282048.0000\n",
      "Epoch 785/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 821096448.000 - 0s 65us/step - loss: 787523569.0076 - val_loss: 707280960.0000\n",
      "Epoch 786/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 788849024.000 - 0s 55us/step - loss: 787522632.7053 - val_loss: 707280064.0000\n",
      "Epoch 787/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 731777536.000 - 0s 63us/step - loss: 787521694.9521 - val_loss: 707279168.0000\n",
      "Epoch 788/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774308480.000 - 0s 58us/step - loss: 787520734.4685 - val_loss: 707278208.0000\n",
      "Epoch 789/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 758026240.000 - 0s 58us/step - loss: 787519820.4131 - val_loss: 707277248.0000\n",
      "Epoch 790/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 759154752.000 - 0s 58us/step - loss: 787518878.7909 - val_loss: 707276352.0000\n",
      "Epoch 791/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790554560.000 - 0s 60us/step - loss: 787517948.7758 - val_loss: 707275392.0000\n",
      "Epoch 792/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781910912.000 - 0s 63us/step - loss: 787517042.4584 - val_loss: 707274496.0000\n",
      "Epoch 793/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 766627392.000 - 0s 60us/step - loss: 787516105.9950 - val_loss: 707273472.0000\n",
      "Epoch 794/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798051968.000 - 0s 50us/step - loss: 787515202.0957 - val_loss: 707272576.0000\n",
      "Epoch 795/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772270464.000 - 0s 55us/step - loss: 787514257.4106 - val_loss: 707271616.0000\n",
      "Epoch 796/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 737711040.000 - 0s 53us/step - loss: 787513360.2821 - val_loss: 707270720.0000\n",
      "Epoch 797/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 772121728.000 - 0s 55us/step - loss: 787512394.1562 - val_loss: 707269760.0000\n",
      "Epoch 798/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 813625472.000 - 0s 55us/step - loss: 787511465.5919 - val_loss: 707268800.0000\n",
      "Epoch 799/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807572352.000 - 0s 50us/step - loss: 787510601.1889 - val_loss: 707267840.0000\n",
      "Epoch 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - ETA: 0s - loss: 763510528.000 - 0s 58us/step - loss: 787509586.8615 - val_loss: 707266880.0000\n",
      "Epoch 801/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802382592.000 - 0s 53us/step - loss: 787508611.0630 - val_loss: 707265984.0000\n",
      "Epoch 802/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 769132160.000 - 0s 50us/step - loss: 787507689.9144 - val_loss: 707265088.0000\n",
      "Epoch 803/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773709376.000 - 0s 53us/step - loss: 787506739.9093 - val_loss: 707264064.0000\n",
      "Epoch 804/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 761196224.000 - 0s 53us/step - loss: 787505829.5617 - val_loss: 707263104.0000\n",
      "Epoch 805/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756563968.000 - 0s 50us/step - loss: 787504882.9421 - val_loss: 707262208.0000\n",
      "Epoch 806/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795865856.000 - 0s 53us/step - loss: 787503970.9824 - val_loss: 707261184.0000\n",
      "Epoch 807/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 760984064.000 - 0s 53us/step - loss: 787503013.8841 - val_loss: 707260288.0000\n",
      "Epoch 808/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799918144.000 - 0s 55us/step - loss: 787502045.8237 - val_loss: 707259328.0000\n",
      "Epoch 809/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 803481216.000 - 0s 53us/step - loss: 787501119.8388 - val_loss: 707258304.0000\n",
      "Epoch 810/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 759047040.000 - 0s 50us/step - loss: 787500170.9622 - val_loss: 707257408.0000\n",
      "Epoch 811/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 711652736.000 - 0s 50us/step - loss: 787499206.2872 - val_loss: 707256512.0000\n",
      "Epoch 812/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 744897920.000 - 0s 50us/step - loss: 787498328.8262 - val_loss: 707255552.0000\n",
      "Epoch 813/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 737344256.000 - 0s 58us/step - loss: 787497377.8539 - val_loss: 707254528.0000\n",
      "Epoch 814/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797044096.000 - 0s 55us/step - loss: 787496422.8514 - val_loss: 707253696.0000\n",
      "Epoch 815/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780606976.000 - 0s 50us/step - loss: 787495536.2015 - val_loss: 707252736.0000\n",
      "Epoch 816/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794331712.000 - 0s 55us/step - loss: 787494581.6826 - val_loss: 707251776.0000\n",
      "Epoch 817/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777906304.000 - 0s 53us/step - loss: 787493657.6322 - val_loss: 707250880.0000\n",
      "Epoch 818/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 763033600.000 - 0s 55us/step - loss: 787492763.7280 - val_loss: 707249984.0000\n",
      "Epoch 819/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782313984.000 - 0s 53us/step - loss: 787491831.9395 - val_loss: 707248960.0000\n",
      "Epoch 820/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798147840.000 - 0s 53us/step - loss: 787490892.5743 - val_loss: 707248064.0000\n",
      "Epoch 821/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794740736.000 - 0s 50us/step - loss: 787489984.8060 - val_loss: 707247104.0000\n",
      "Epoch 822/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 813024640.000 - 0s 50us/step - loss: 787489072.3627 - val_loss: 707246208.0000\n",
      "Epoch 823/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809727232.000 - 0s 55us/step - loss: 787488117.8438 - val_loss: 707245184.0000\n",
      "Epoch 824/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 788308672.000 - 0s 50us/step - loss: 787487169.1285 - val_loss: 707244288.0000\n",
      "Epoch 825/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781279296.000 - 0s 50us/step - loss: 787486241.0479 - val_loss: 707243264.0000\n",
      "Epoch 826/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 771572480.000 - 0s 55us/step - loss: 787485291.3652 - val_loss: 707242432.0000\n",
      "Epoch 827/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801010688.000 - 0s 53us/step - loss: 787484368.6045 - val_loss: 707241472.0000\n",
      "Epoch 828/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 808022208.000 - 0s 55us/step - loss: 787483417.4710 - val_loss: 707240512.0000\n",
      "Epoch 829/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 829328128.000 - 0s 53us/step - loss: 787482479.7179 - val_loss: 707239552.0000\n",
      "Epoch 830/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795900416.000 - 0s 53us/step - loss: 787481591.7783 - val_loss: 707238656.0000\n",
      "Epoch 831/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783055744.000 - 0s 50us/step - loss: 787480642.0957 - val_loss: 707237696.0000\n",
      "Epoch 832/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 802072192.000 - 0s 55us/step - loss: 787479709.8237 - val_loss: 707236800.0000\n",
      "Epoch 833/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796388736.000 - 0s 53us/step - loss: 787478804.9572 - val_loss: 707235840.0000\n",
      "Epoch 834/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791354816.000 - 0s 50us/step - loss: 787477864.9471 - val_loss: 707234880.0000\n",
      "Epoch 835/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767681408.000 - 0s 53us/step - loss: 787476934.9320 - val_loss: 707233920.0000\n",
      "Epoch 836/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 827679360.000 - 0s 48us/step - loss: 787476030.2267 - val_loss: 707232960.0000\n",
      "Epoch 837/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 758459072.000 - 0s 53us/step - loss: 787475009.1285 - val_loss: 707232064.0000\n",
      "Epoch 838/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799255808.000 - 0s 55us/step - loss: 787474138.1159 - val_loss: 707231168.0000\n",
      "Epoch 839/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798831360.000 - 0s 50us/step - loss: 787473191.0126 - val_loss: 707230144.0000\n",
      "Epoch 840/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 765207424.000 - 0s 53us/step - loss: 787472240.0403 - val_loss: 707229248.0000\n",
      "Epoch 841/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 739873792.000 - 0s 60us/step - loss: 787471358.0655 - val_loss: 707228288.0000\n",
      "Epoch 842/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 744547456.000 - 0s 53us/step - loss: 787470438.3678 - val_loss: 707227392.0000\n",
      "Epoch 843/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801616256.000 - 0s 53us/step - loss: 787469469.0176 - val_loss: 707226432.0000\n",
      "Epoch 844/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 818813312.000 - 0s 55us/step - loss: 787468550.4484 - val_loss: 707225536.0000\n",
      "Epoch 845/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 845673984.000 - 0s 55us/step - loss: 787467604.9572 - val_loss: 707224640.0000\n",
      "Epoch 846/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 752021824.000 - 0s 53us/step - loss: 787466708.7960 - val_loss: 707223616.0000\n",
      "Epoch 847/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795278592.000 - 0s 53us/step - loss: 787465785.5516 - val_loss: 707222720.0000\n",
      "Epoch 848/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799285184.000 - 0s 55us/step - loss: 787464842.4786 - val_loss: 707221760.0000\n",
      "Epoch 849/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 791684736.000 - 0s 55us/step - loss: 787463912.4635 - val_loss: 707220864.0000\n",
      "Epoch 850/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756715072.000 - 0s 55us/step - loss: 787462964.5542 - val_loss: 707219840.0000\n",
      "Epoch 851/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807629696.000 - 0s 58us/step - loss: 787462058.8816 - val_loss: 707218880.0000\n",
      "Epoch 852/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795305344.000 - 0s 58us/step - loss: 787461117.7431 - val_loss: 707218048.0000\n",
      "Epoch 853/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 758369344.000 - 0s 55us/step - loss: 787460239.4761 - val_loss: 707217088.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 854/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811362432.000 - 0s 55us/step - loss: 787459274.1562 - val_loss: 707216192.0000\n",
      "Epoch 855/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 822620288.000 - 0s 55us/step - loss: 787458388.9572 - val_loss: 707215296.0000\n",
      "Epoch 856/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774776640.000 - 0s 53us/step - loss: 787457466.0353 - val_loss: 707214336.0000\n",
      "Epoch 857/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801664768.000 - 0s 53us/step - loss: 787456526.0252 - val_loss: 707213312.0000\n",
      "Epoch 858/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 819107840.000 - 0s 53us/step - loss: 787455592.4635 - val_loss: 707212352.0000\n",
      "Epoch 859/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 821089152.000 - 0s 53us/step - loss: 787454694.2065 - val_loss: 707211520.0000\n",
      "Epoch 860/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779179136.000 - 0s 55us/step - loss: 787453755.9698 - val_loss: 707210560.0000\n",
      "Epoch 861/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 766874112.000 - 0s 53us/step - loss: 787452861.4207 - val_loss: 707209664.0000\n",
      "Epoch 862/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767315392.000 - 0s 55us/step - loss: 787451900.9370 - val_loss: 707208704.0000\n",
      "Epoch 863/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768773184.000 - 0s 53us/step - loss: 787450998.8111 - val_loss: 707207744.0000\n",
      "Epoch 864/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799977856.000 - 0s 48us/step - loss: 787450023.6574 - val_loss: 707206784.0000\n",
      "Epoch 865/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778368000.000 - 0s 55us/step - loss: 787449128.7859 - val_loss: 707205952.0000\n",
      "Epoch 866/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768442368.000 - 0s 53us/step - loss: 787448221.5013 - val_loss: 707204992.0000\n",
      "Epoch 867/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814590912.000 - 0s 53us/step - loss: 787447281.3300 - val_loss: 707204032.0000\n",
      "Epoch 868/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756686784.000 - 0s 53us/step - loss: 787446403.0630 - val_loss: 707203008.0000\n",
      "Epoch 869/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 757466624.000 - 0s 53us/step - loss: 787445456.2821 - val_loss: 707202112.0000\n",
      "Epoch 870/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 753770752.000 - 0s 55us/step - loss: 787444477.7431 - val_loss: 707201216.0000\n",
      "Epoch 871/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767908864.000 - 0s 53us/step - loss: 787443563.3652 - val_loss: 707200256.0000\n",
      "Epoch 872/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783289856.000 - 0s 55us/step - loss: 787442623.0327 - val_loss: 707199232.0000\n",
      "Epoch 873/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 831621248.000 - 0s 53us/step - loss: 787441693.1788 - val_loss: 707198400.0000\n",
      "Epoch 874/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807823936.000 - 0s 53us/step - loss: 787440764.4534 - val_loss: 707197440.0000\n",
      "Epoch 875/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 776098816.000 - 0s 58us/step - loss: 787439817.9950 - val_loss: 707196480.0000\n",
      "Epoch 876/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796785536.000 - 0s 50us/step - loss: 787438908.2922 - val_loss: 707195520.0000\n",
      "Epoch 877/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755475712.000 - 0s 53us/step - loss: 787437976.0202 - val_loss: 707194624.0000\n",
      "Epoch 878/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 817230720.000 - 0s 53us/step - loss: 787436989.9043 - val_loss: 707193664.0000\n",
      "Epoch 879/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 771847936.000 - 0s 53us/step - loss: 787436091.9698 - val_loss: 707192768.0000\n",
      "Epoch 880/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794720448.000 - 0s 53us/step - loss: 787435180.4937 - val_loss: 707191808.0000\n",
      "Epoch 881/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 789425536.000 - 0s 50us/step - loss: 787434237.4207 - val_loss: 707190848.0000\n",
      "Epoch 882/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809229312.000 - 0s 53us/step - loss: 787433344.9673 - val_loss: 707189888.0000\n",
      "Epoch 883/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 812005440.000 - 0s 53us/step - loss: 787432387.8690 - val_loss: 707188992.0000\n",
      "Epoch 884/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 845491328.000 - 0s 60us/step - loss: 787431441.7330 - val_loss: 707188096.0000\n",
      "Epoch 885/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 759366144.000 - 0s 55us/step - loss: 787430528.8060 - val_loss: 707187072.0000\n",
      "Epoch 886/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792669056.000 - 0s 53us/step - loss: 787429597.0176 - val_loss: 707186176.0000\n",
      "Epoch 887/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 822668544.000 - 0s 53us/step - loss: 787428665.0680 - val_loss: 707185216.0000\n",
      "Epoch 888/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809737088.000 - 0s 50us/step - loss: 787427705.3904 - val_loss: 707184320.0000\n",
      "Epoch 889/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 727374720.000 - 0s 55us/step - loss: 787426762.9622 - val_loss: 707183360.0000\n",
      "Epoch 890/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 781705792.000 - 0s 53us/step - loss: 787425835.3652 - val_loss: 707182336.0000\n",
      "Epoch 891/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762334400.000 - 0s 53us/step - loss: 787424925.9849 - val_loss: 707181504.0000\n",
      "Epoch 892/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 783511360.000 - 0s 53us/step - loss: 787423984.5239 - val_loss: 707180544.0000\n",
      "Epoch 893/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793261248.000 - 0s 53us/step - loss: 787423019.8489 - val_loss: 707179520.0000\n",
      "Epoch 894/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 753109440.000 - 0s 53us/step - loss: 787422051.6272 - val_loss: 707178560.0000\n",
      "Epoch 895/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 838734400.000 - 0s 53us/step - loss: 787421105.9748 - val_loss: 707177536.0000\n",
      "Epoch 896/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814174720.000 - 0s 53us/step - loss: 787420163.0630 - val_loss: 707176640.0000\n",
      "Epoch 897/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811927616.000 - 0s 55us/step - loss: 787419233.2091 - val_loss: 707175744.0000\n",
      "Epoch 898/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 828039360.000 - 0s 55us/step - loss: 787418299.8086 - val_loss: 707174720.0000\n",
      "Epoch 899/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785437888.000 - 0s 53us/step - loss: 787417319.8186 - val_loss: 707173824.0000\n",
      "Epoch 900/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 788663168.000 - 0s 55us/step - loss: 787416425.2695 - val_loss: 707172928.0000\n",
      "Epoch 901/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762092160.000 - 0s 53us/step - loss: 787415472.8463 - val_loss: 707171904.0000\n",
      "Epoch 902/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 779201792.000 - 0s 53us/step - loss: 787414505.2695 - val_loss: 707170944.0000\n",
      "Epoch 903/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 825894464.000 - 0s 50us/step - loss: 787413556.7154 - val_loss: 707169920.0000\n",
      "Epoch 904/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 844777856.000 - 0s 55us/step - loss: 787412647.3350 - val_loss: 707169024.0000\n",
      "Epoch 905/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774612032.000 - 0s 58us/step - loss: 787411744.4030 - val_loss: 707168128.0000\n",
      "Epoch 906/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796283904.000 - 0s 53us/step - loss: 787410783.9194 - val_loss: 707167168.0000\n",
      "Epoch 907/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - ETA: 0s - loss: 806277888.000 - 0s 55us/step - loss: 787409823.7582 - val_loss: 707166208.0000\n",
      "Epoch 908/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 821631488.000 - 0s 48us/step - loss: 787408942.5894 - val_loss: 707165248.0000\n",
      "Epoch 909/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792931776.000 - 0s 55us/step - loss: 787407993.5516 - val_loss: 707164352.0000\n",
      "Epoch 910/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794378816.000 - 0s 53us/step - loss: 787407093.0378 - val_loss: 707163392.0000\n",
      "Epoch 911/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 768538624.000 - 0s 53us/step - loss: 787406162.2166 - val_loss: 707162560.0000\n",
      "Epoch 912/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773631424.000 - 0s 55us/step - loss: 787405243.4861 - val_loss: 707161600.0000\n",
      "Epoch 913/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 756538176.000 - 0s 55us/step - loss: 787404306.5390 - val_loss: 707160640.0000\n",
      "Epoch 914/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 810930368.000 - 0s 50us/step - loss: 787403371.0428 - val_loss: 707159616.0000\n",
      "Epoch 915/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793507840.000 - 0s 55us/step - loss: 787402432.4836 - val_loss: 707158784.0000\n",
      "Epoch 916/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 765113600.000 - 0s 50us/step - loss: 787401514.7204 - val_loss: 707157824.0000\n",
      "Epoch 917/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794208512.000 - 0s 55us/step - loss: 787400600.5038 - val_loss: 707156928.0000\n",
      "Epoch 918/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798675648.000 - 0s 53us/step - loss: 787399682.2569 - val_loss: 707156032.0000\n",
      "Epoch 919/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 746134400.000 - 0s 50us/step - loss: 787398749.0176 - val_loss: 707155072.0000\n",
      "Epoch 920/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 788015232.000 - 0s 58us/step - loss: 787397864.4635 - val_loss: 707154048.0000\n",
      "Epoch 921/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 775754880.000 - 0s 50us/step - loss: 787396927.0327 - val_loss: 707153152.0000\n",
      "Epoch 922/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795876864.000 - 0s 58us/step - loss: 787395975.5768 - val_loss: 707152256.0000\n",
      "Epoch 923/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 762740992.000 - 0s 55us/step - loss: 787395071.5164 - val_loss: 707151296.0000\n",
      "Epoch 924/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767577216.000 - 0s 55us/step - loss: 787394120.8665 - val_loss: 707150336.0000\n",
      "Epoch 925/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 818134016.000 - 0s 55us/step - loss: 787393239.8589 - val_loss: 707149504.0000\n",
      "Epoch 926/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 761719424.000 - 0s 55us/step - loss: 787392290.6599 - val_loss: 707148544.0000\n",
      "Epoch 927/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792460736.000 - 0s 58us/step - loss: 787391387.8892 - val_loss: 707147520.0000\n",
      "Epoch 928/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 744560704.000 - 0s 50us/step - loss: 787390469.3199 - val_loss: 707146688.0000\n",
      "Epoch 929/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 851837056.000 - 0s 53us/step - loss: 787389489.0076 - val_loss: 707145728.0000\n",
      "Epoch 930/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 778395008.000 - 0s 50us/step - loss: 787388580.9169 - val_loss: 707144768.0000\n",
      "Epoch 931/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 784706240.000 - 0s 55us/step - loss: 787387711.8388 - val_loss: 707143808.0000\n",
      "Epoch 932/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 809832320.000 - 0s 53us/step - loss: 787386708.1511 - val_loss: 707142912.0000\n",
      "Epoch 933/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 742547200.000 - 0s 58us/step - loss: 787385778.9421 - val_loss: 707142016.0000\n",
      "Epoch 934/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 750271040.000 - 0s 55us/step - loss: 787384871.0126 - val_loss: 707141056.0000\n",
      "Epoch 935/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795832960.000 - 0s 63us/step - loss: 787383954.7003 - val_loss: 707140096.0000\n",
      "Epoch 936/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 834586368.000 - 0s 60us/step - loss: 787383056.1209 - val_loss: 707139200.0000\n",
      "Epoch 937/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 774238976.000 - 0s 63us/step - loss: 787382049.2091 - val_loss: 707138176.0000\n",
      "Epoch 938/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 826253952.000 - 0s 63us/step - loss: 787381111.4559 - val_loss: 707137216.0000\n",
      "Epoch 939/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 807139712.000 - 0s 58us/step - loss: 787380188.6952 - val_loss: 707136256.0000\n",
      "Epoch 940/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773228416.000 - 0s 53us/step - loss: 787379207.0932 - val_loss: 707135296.0000\n",
      "Epoch 941/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 827630976.000 - 0s 53us/step - loss: 787378326.4081 - val_loss: 707134400.0000\n",
      "Epoch 942/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 767569280.000 - 0s 53us/step - loss: 787377354.9622 - val_loss: 707133440.0000\n",
      "Epoch 943/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 813643648.000 - 0s 55us/step - loss: 787376416.0806 - val_loss: 707132480.0000\n",
      "Epoch 944/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 795253888.000 - 0s 53us/step - loss: 787375495.7380 - val_loss: 707131584.0000\n",
      "Epoch 945/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 741366656.000 - 0s 55us/step - loss: 787374565.4005 - val_loss: 707130624.0000\n",
      "Epoch 946/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 822827776.000 - 0s 50us/step - loss: 787373685.0378 - val_loss: 707129728.0000\n",
      "Epoch 947/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814081088.000 - 0s 53us/step - loss: 787372771.9496 - val_loss: 707128832.0000\n",
      "Epoch 948/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 748665344.000 - 0s 60us/step - loss: 787371825.8136 - val_loss: 707127872.0000\n",
      "Epoch 949/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794118400.000 - 0s 55us/step - loss: 787370914.3375 - val_loss: 707126976.0000\n",
      "Epoch 950/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 758364672.000 - 0s 58us/step - loss: 787369969.0076 - val_loss: 707126080.0000\n",
      "Epoch 951/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 822803200.000 - 0s 75us/step - loss: 787369115.5668 - val_loss: 707125056.0000\n",
      "Epoch 952/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782551552.000 - 0s 60us/step - loss: 787368144.9270 - val_loss: 707124160.0000\n",
      "Epoch 953/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 829914304.000 - 0s 63us/step - loss: 787367244.7355 - val_loss: 707123200.0000\n",
      "Epoch 954/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 792399360.000 - 0s 60us/step - loss: 787366328.9068 - val_loss: 707122304.0000\n",
      "Epoch 955/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 761654784.000 - 0s 60us/step - loss: 787365366.0050 - val_loss: 707121408.0000\n",
      "Epoch 956/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755932864.000 - 0s 58us/step - loss: 787364449.5315 - val_loss: 707120384.0000\n",
      "Epoch 957/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790204608.000 - 0s 55us/step - loss: 787363493.5617 - val_loss: 707119488.0000\n",
      "Epoch 958/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790914176.000 - 0s 60us/step - loss: 787362644.1511 - val_loss: 707118528.0000\n",
      "Epoch 959/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787125376.000 - 0s 50us/step - loss: 787361661.4207 - val_loss: 707117632.0000\n",
      "Epoch 960/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 775962304.000 - 0s 53us/step - loss: 787360719.3149 - val_loss: 707116608.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 747354816.000 - 0s 55us/step - loss: 787359815.2544 - val_loss: 707115648.0000\n",
      "Epoch 962/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 750414016.000 - 0s 55us/step - loss: 787358857.1889 - val_loss: 707114752.0000\n",
      "Epoch 963/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 797472768.000 - 0s 50us/step - loss: 787357935.2343 - val_loss: 707113856.0000\n",
      "Epoch 964/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 739369216.000 - 0s 48us/step - loss: 787357030.6902 - val_loss: 707112896.0000\n",
      "Epoch 965/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777630080.000 - 0s 58us/step - loss: 787356078.2670 - val_loss: 707112000.0000\n",
      "Epoch 966/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 836152192.000 - 0s 53us/step - loss: 787355157.4408 - val_loss: 707110976.0000\n",
      "Epoch 967/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777891712.000 - 0s 63us/step - loss: 787354231.2947 - val_loss: 707110080.0000\n",
      "Epoch 968/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770551360.000 - 0s 60us/step - loss: 787353309.3401 - val_loss: 707109120.0000\n",
      "Epoch 969/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770572288.000 - 0s 63us/step - loss: 787352384.1612 - val_loss: 707108288.0000\n",
      "Epoch 970/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 819623744.000 - 0s 63us/step - loss: 787351438.5088 - val_loss: 707107264.0000\n",
      "Epoch 971/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 830095552.000 - 0s 60us/step - loss: 787350542.8312 - val_loss: 707106304.0000\n",
      "Epoch 972/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 780080128.000 - 0s 60us/step - loss: 787349589.7632 - val_loss: 707105408.0000\n",
      "Epoch 973/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 773853952.000 - 0s 55us/step - loss: 787348646.8514 - val_loss: 707104512.0000\n",
      "Epoch 974/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 834259520.000 - 0s 55us/step - loss: 787347745.8539 - val_loss: 707103552.0000\n",
      "Epoch 975/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 801525632.000 - 0s 55us/step - loss: 787346832.6045 - val_loss: 707102528.0000\n",
      "Epoch 976/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 786586752.000 - 0s 55us/step - loss: 787345882.1159 - val_loss: 707101632.0000\n",
      "Epoch 977/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 782925184.000 - 0s 53us/step - loss: 787344980.6348 - val_loss: 707100736.0000\n",
      "Epoch 978/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 794542912.000 - 0s 53us/step - loss: 787344008.2217 - val_loss: 707099776.0000\n",
      "Epoch 979/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 777950208.000 - 0s 53us/step - loss: 787343117.5416 - val_loss: 707098880.0000\n",
      "Epoch 980/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798013568.000 - 0s 55us/step - loss: 787342199.4559 - val_loss: 707097856.0000\n",
      "Epoch 981/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 753701504.000 - 0s 50us/step - loss: 787341239.2947 - val_loss: 707097024.0000\n",
      "Epoch 982/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 742992000.000 - 0s 60us/step - loss: 787340341.8438 - val_loss: 707096000.0000\n",
      "Epoch 983/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 796982976.000 - 0s 60us/step - loss: 787339386.1965 - val_loss: 707095104.0000\n",
      "Epoch 984/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 793302656.000 - 0s 63us/step - loss: 787338428.1310 - val_loss: 707094144.0000\n",
      "Epoch 985/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 814890496.000 - 0s 68us/step - loss: 787337546.9622 - val_loss: 707093184.0000\n",
      "Epoch 986/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799145088.000 - 0s 60us/step - loss: 787336580.9975 - val_loss: 707092224.0000\n",
      "Epoch 987/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 798109568.000 - 0s 63us/step - loss: 787335636.7960 - val_loss: 707091264.0000\n",
      "Epoch 988/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 755625728.000 - 0s 68us/step - loss: 787334720.0000 - val_loss: 707090368.0000\n",
      "Epoch 989/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770863424.000 - 0s 58us/step - loss: 787333764.3526 - val_loss: 707089408.0000\n",
      "Epoch 990/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 757705024.000 - 0s 60us/step - loss: 787332836.5945 - val_loss: 707088448.0000\n",
      "Epoch 991/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 787197184.000 - 0s 63us/step - loss: 787331896.5844 - val_loss: 707087616.0000\n",
      "Epoch 992/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 811053312.000 - 0s 55us/step - loss: 787331029.9244 - val_loss: 707086720.0000\n",
      "Epoch 993/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 747891968.000 - 0s 53us/step - loss: 787330118.6096 - val_loss: 707085760.0000\n",
      "Epoch 994/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 742440704.000 - 0s 55us/step - loss: 787329152.8060 - val_loss: 707084736.0000\n",
      "Epoch 995/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 799819712.000 - 0s 53us/step - loss: 787328230.0453 - val_loss: 707083840.0000\n",
      "Epoch 996/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790191808.000 - 0s 58us/step - loss: 787327313.8942 - val_loss: 707082944.0000\n",
      "Epoch 997/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 790934912.000 - 0s 53us/step - loss: 787326422.0856 - val_loss: 707081984.0000\n",
      "Epoch 998/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 785729088.000 - 0s 58us/step - loss: 787325470.1461 - val_loss: 707081088.0000\n",
      "Epoch 999/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 770536320.000 - 0s 55us/step - loss: 787324494.9924 - val_loss: 707080128.0000\n",
      "Epoch 1000/1000\n",
      "397/397 [==============================] - ETA: 0s - loss: 749494784.000 - 0s 55us/step - loss: 787323607.5365 - val_loss: 707079168.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2294500ca58>"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from 2 dimmension to 3 dimension\n",
    "Y_train = Y_train[:,:,np.newaxis]\n",
    "Y_val = Y_val[:,:,np.newaxis]\n",
    "\n",
    "model = buildManyToManyModel(X_train.shape)\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size=128, validation_data=(X_val, Y_val), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_val = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 7, 1)"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predict_val).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 7)"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_val = predict_val.reshape((44,7))\n",
    "predict_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7)"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = predict_val[36:]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = [\"20190402\", \"20190403\", \"20190404\", \"20190405\", \"20190406\", \"20190407\", \"20190408\"]\n",
    "dfdict = {\"date1\": date1}\n",
    "# 建立 data frame\n",
    "df0402 = pd.DataFrame(dfdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0402.iloc[:,0] = pd.to_datetime(df0402.iloc[:,0], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-04-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date1\n",
       "0 2019-04-02\n",
       "1 2019-04-03\n",
       "2 2019-04-04\n",
       "3 2019-04-05\n",
       "4 2019-04-06\n",
       "5 2019-04-07\n",
       "6 2019-04-08"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0402[\"year\"] = df0402[\"date1\"].dt.year\n",
    "df0402[\"month\"] = df0402[\"date1\"].dt.month\n",
    "df0402[\"date\"] = df0402[\"date1\"].dt.day\n",
    "df0402[\"day\"] = df0402[\"date1\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0402.iloc[:,3:] = normalize(df0402.iloc[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date1</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-06</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date1  year  month      date       day\n",
       "0 2019-04-02  2019      4  0.000000  0.166667\n",
       "1 2019-04-03  2019      4  0.166667  0.333333\n",
       "2 2019-04-04  2019      4  0.333333  0.500000\n",
       "3 2019-04-05  2019      4  0.500000  0.666667\n",
       "4 2019-04-06  2019      4  0.666667  0.833333\n",
       "5 2019-04-07  2019      4  0.833333  1.000000\n",
       "6 2019-04-08  2019      4  1.000000  0.000000"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0402.iloc[:,1] = (df0402.iloc[:,1]-2018)/1\n",
    "df0402.iloc[:,2] = (df0402.iloc[:,2]-1)/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0402 = df0402.drop([\"date1\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df0402 = df0402.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4)"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0402.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
